{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Chapter Summaries > Class tries to learn everyone's name", "content": "Title: CS224V Lecture 3 > Chapter Summaries > Class tries to learn everyone's name\n\nContent: All right, I'm trying to learn everybody's name. That's the only, you know, where we actually attempt to learn people's names. How many people have attempted it? Oh, pretty good. Is it going okay?", "block_metadata": {"id": "CS224V_Lecture_3_>_Chapter_Summaries_>_Class_tries_to_learn_everyone's_name", "document_type": "chapter summary", "lecture_number": 3, "start_ms": 213105, "end_ms": 242635}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Chapter Summaries > Autonomous Agents in the Web, Society", "content": "Title: CS224V Lecture 3 > Chapter Summaries > Autonomous Agents in the Web, Society\n\nContent: This is a third lecture, and we're going to talk about agents. What we're focusing on are the kinds of things that you do on the web and on your assistants. In order to provide this as an automated agent, we need the understand, apply, and the analyze.", "block_metadata": {"id": "CS224V_Lecture_3_>_Chapter_Summaries_>_Autonomous_Agents_in_the_Web,_Society", "document_type": "chapter summary", "lecture_number": 3, "start_ms": 243215, "end_ms": 345135}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Chapter Summaries > The state of the art in task assistance", "content": "Title: CS224V Lecture 3 > Chapter Summaries > The state of the art in task assistance\n\nContent: The whole idea is to give you the state of the art in terms of knowledge and task assistance. And you will have some intent on experience in building the agents using the tools that we have and that we'll be talking about. You don't have to use the tools, but we think that it is helpful for a lot of projects.", "block_metadata": {"id": "CS224V_Lecture_3_>_Chapter_Summaries_>_The_state_of_the_art_in_task_assistance", "document_type": "chapter summary", "lecture_number": 3, "start_ms": 346715, "end_ms": 470505}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Chapter Summaries > The Agents of Natural Language Virtual Assistants", "content": "Title: CS224V Lecture 3 > Chapter Summaries > The Agents of Natural Language Virtual Assistants\n\nContent: A lot of the work went on answering questions. Answering questions are actually harder than just curating and summarizing information that it reads on the web. Then if you look at virtual assistants, they are actually performing functions.", "block_metadata": {"id": "CS224V_Lecture_3_>_Chapter_Summaries_>_The_Agents_of_Natural_Language_Virtual_Assistants", "document_type": "chapter summary", "lecture_number": 3, "start_ms": 471445, "end_ms": 712235}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Chapter Summaries > Integrated Knowledge and Task Agents", "content": "Title: CS224V Lecture 3 > Chapter Summaries > Integrated Knowledge and Task Agents\n\nContent: Project allows you to have integration of knowledge and tasks. GPT is actually good with social, with tasks like persuasion. But the problem is that it is not factual. Going forward there will be all kinds of things that you want to achieve.", "block_metadata": {"id": "CS224V_Lecture_3_>_Chapter_Summaries_>_Integrated_Knowledge_and_Task_Agents", "document_type": "chapter summary", "lecture_number": 3, "start_ms": 712655, "end_ms": 865565}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Chapter Summaries > Knowledge and Task Oriented Agents", "content": "Title: CS224V Lecture 3 > Chapter Summaries > Knowledge and Task Oriented Agents\n\nContent: We will start with knowledge and then APIs and then we're going to do knowledge and task oriented agents. Actually we talked about the free text in the first lecture. We will talk about the details about how you really make it work in the rest of the lecture.", "block_metadata": {"id": "CS224V_Lecture_3_>_Chapter_Summaries_>_Knowledge_and_Task_Oriented_Agents", "document_type": "chapter summary", "lecture_number": 3, "start_ms": 865685, "end_ms": 916923}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Chapter Summaries > Microsoft SQL: Natural Language and Search", "content": "Title: CS224V Lecture 3 > Chapter Summaries > Microsoft SQL: Natural Language and Search\n\nContent: The architecture that we have is that you have information from the outside. There is Wikipedia free text and there is also data. And we're going to take natural language, go through this process called semantic parsing. It translates into formal queries and you go fetch the data.", "block_metadata": {"id": "CS224V_Lecture_3_>_Chapter_Summaries_>_Microsoft_SQL:_Natural_Language_and_Search", "document_type": "chapter summary", "lecture_number": 3, "start_ms": 916979, "end_ms": 1003685}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Chapter Summaries > Knowledge bases and the SQL paradigm", "content": "Title: CS224V Lecture 3 > Chapter Summaries > Knowledge bases and the SQL paradigm\n\nContent: There's just lots of structured data in the world. Schema. org is intended to be structuring information on the web. One idea is to turn all the databases into sentences and use free text analysis over it. It is much better if you natively work with databases.", "block_metadata": {"id": "CS224V_Lecture_3_>_Chapter_Summaries_>_Knowledge_bases_and_the_SQL_paradigm", "document_type": "chapter summary", "lecture_number": 3, "start_ms": 1005265, "end_ms": 1578987}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Chapter Summaries > Neural Semantic Parser for a Knowledge Agent", "content": "Title: CS224V Lecture 3 > Chapter Summaries > Neural Semantic Parser for a Knowledge Agent\n\nContent: A query language is domain independent. What you really would like to do is to say, can we generalize to all the domains? If you show me a restaurant schema, then I answer restaurant questions. But if you give me a hotel schema, I'll answer hotel question. The answer is then turned into nice looking English sentences.", "block_metadata": {"id": "CS224V_Lecture_3_>_Chapter_Summaries_>_Neural_Semantic_Parser_for_a_Knowledge_Agent", "document_type": "chapter summary", "lecture_number": 3, "start_ms": 1579131, "end_ms": 1828175}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Chapter Summaries > Neurosemantic Parser for Natural Language", "content": "Title: CS224V Lecture 3 > Chapter Summaries > Neurosemantic Parser for Natural Language\n\nContent: For example, let's look at a conversation. You're selecting from a restaurant where location is equal to Mountain View. Then later on he says, thanks, we'll be visiting Stanford. How about Palo Alto? Okay, now you have to understand that we are changing from Mountain View to Palo Alto.", "block_metadata": {"id": "CS224V_Lecture_3_>_Chapter_Summaries_>_Neurosemantic_Parser_for_Natural_Language", "document_type": "chapter summary", "lecture_number": 3, "start_ms": 1828295, "end_ms": 1943027}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Chapter Summaries > An agentic query language for Wikidata", "content": "Title: CS224V Lecture 3 > Chapter Summaries > An agentic query language for Wikidata\n\nContent: Wikidata is the largest live Knowledge graph. It has over 100 million entities, 10,000 properties, 25,000 human contributors. The query is with sparkle. We are trying to imitate the expert workers. Can we get AI to help?", "block_metadata": {"id": "CS224V_Lecture_3_>_Chapter_Summaries_>_An_agentic_query_language_for_Wikidata", "document_type": "chapter summary", "lecture_number": 3, "start_ms": 1943211, "end_ms": 2338091}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Chapter Summaries > How do we guarantee completeness in hybrid data queries?", "content": "Title: CS224V Lecture 3 > Chapter Summaries > How do we guarantee completeness in hybrid data queries?\n\nContent: How do we guarantee completeness or maybe like we miss one or two facts? The first thing you do is that whatever you do, you have to describe what it is that you have done. For things that are really hard, we can't. Even the humans have to discuss how to get it done.", "block_metadata": {"id": "CS224V_Lecture_3_>_Chapter_Summaries_>_How_do_we_guarantee_completeness_in_hybrid_data_queries?", "document_type": "chapter summary", "lecture_number": 3, "start_ms": 2338203, "end_ms": 2437625}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Chapter Summaries > Hybrid data", "content": "Title: CS224V Lecture 3 > Chapter Summaries > Hybrid data\n\nContent: For everything that we do almost, there is some free text associated with it. The whole concept here is that you really want to combine the two. Summary function and the answer function. In both you need both forms of information.", "block_metadata": {"id": "CS224V_Lecture_3_>_Chapter_Summaries_>_Hybrid_data", "document_type": "chapter summary", "lecture_number": 3, "start_ms": 2438245, "end_ms": 2703513}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Chapter Summaries > GPT for natural language queries", "content": "Title: CS224V Lecture 3 > Chapter Summaries > GPT for natural language queries\n\nContent: GPT uses a neural model to semantically parse natural language into formal queries. It works with different databases. It's domain independent Q and A against databases. The data can be accessed via data in databases or query languages.", "block_metadata": {"id": "CS224V_Lecture_3_>_Chapter_Summaries_>_GPT_for_natural_language_queries", "document_type": "chapter summary", "lecture_number": 3, "start_ms": 2703689, "end_ms": 2973415}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Chapter Summaries > API Calls and Neural Semantic Parser", "content": "Title: CS224V Lecture 3 > Chapter Summaries > API Calls and Neural Semantic Parser\n\nContent: Let's talk about API calls. Is this the same thing as like function calling or tool calling? This is function calling. We're looking for the signature parameterized semantic parsing that translates natural language to QL for a given set of API signatures.", "block_metadata": {"id": "CS224V_Lecture_3_>_Chapter_Summaries_>_API_Calls_and_Neural_Semantic_Parser", "document_type": "chapter summary", "lecture_number": 3, "start_ms": 2974235, "end_ms": 3201069}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Chapter Summaries > Knowledge plus Task Oriented Agents", "content": "Title: CS224V Lecture 3 > Chapter Summaries > Knowledge plus Task Oriented Agents\n\nContent: All right, so let's talk about knowledge plus task oriented agents. You can think of as a task agent booking a restaurant. A lot of times tasks cannot be just done by asking you for the parameters in a function call. And that's why we are very keen on having a task and knowledge oriented agent.", "block_metadata": {"id": "CS224V_Lecture_3_>_Chapter_Summaries_>_Knowledge_plus_Task_Oriented_Agents", "document_type": "chapter summary", "lecture_number": 3, "start_ms": 3201197, "end_ms": 3301685}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Chapter Summaries > Course Enrollment", "content": "Title: CS224V Lecture 3 > Chapter Summaries > Course Enrollment\n\nContent: In real life this is an example of a question or answer that you can get. What course would you like to understand? I'm studying computer science. What are some of the options that require the least amount of work? How does the agent answer the question?", "block_metadata": {"id": "CS224V_Lecture_3_>_Chapter_Summaries_>_Course_Enrollment", "document_type": "chapter summary", "lecture_number": 3, "start_ms": 3302785, "end_ms": 3410135}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Chapter Summaries > How to create a task-based agent for enrollment", "content": "Title: CS224V Lecture 3 > Chapter Summaries > How to create a task-based agent for enrollment\n\nContent: An agent can help you enroll, but at the same time answer all the questions that you may have from all the databases. The task itself seems simple. The hard thing is the integration with the knowledge. It actually has to complete a task.", "block_metadata": {"id": "CS224V_Lecture_3_>_Chapter_Summaries_>_How_to_create_a_task-based_agent_for_enrollment", "document_type": "chapter summary", "lecture_number": 3, "start_ms": 3410215, "end_ms": 3754627}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Chapter Summaries > An agent with a semantic parser", "content": "Title: CS224V Lecture 3 > Chapter Summaries > An agent with a semantic parser\n\nContent: The agent has three parts. The first one is a semantic parser. It needs to be very responsive. What the user says, get higher priorities. There are many possible dialogues. Even for a task with only a few parameters. How do we build it?", "block_metadata": {"id": "CS224V_Lecture_3_>_Chapter_Summaries_>_An_agent_with_a_semantic_parser", "document_type": "chapter summary", "lecture_number": 3, "start_ms": 3754691, "end_ms": 4048531}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Chapter Summaries > GENIE Worksheet 2, The semantic parser", "content": "Title: CS224V Lecture 3 > Chapter Summaries > GENIE Worksheet 2, The semantic parser\n\nContent: Amir: The key idea here is that we have to have a representation that is good for programmer and good for implementation. What the agent has to do is that as it listens to the user, it fills in the worksheets and that represents a dialogue state. This information is also used to decide what the agent needs to do next.", "block_metadata": {"id": "CS224V_Lecture_3_>_Chapter_Summaries_>_GENIE_Worksheet_2,_The_semantic_parser", "document_type": "chapter summary", "lecture_number": 3, "start_ms": 4048643, "end_ms": 4451331}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Chapter Summaries > An agent with a Natural Language", "content": "Title: CS224V Lecture 3 > Chapter Summaries > An agent with a Natural Language\n\nContent: G and E is using LLM for everything that has to do with natural language. The agent policy decides what to do. When you have a system like this, it automatically handles the kind of conversations I showed you. We are able to capture integration of knowledge requests as well as API calls.", "block_metadata": {"id": "CS224V_Lecture_3_>_Chapter_Summaries_>_An_agent_with_a_Natural_Language", "document_type": "chapter summary", "lecture_number": 3, "start_ms": 4451523, "end_ms": 4957423}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Chapter Summaries > Questions for the President", "content": "Title: CS224V Lecture 3 > Chapter Summaries > Questions for the President\n\nContent: Okay. All right. And well, thank you. And I will see you on Wednesday. It.", "block_metadata": {"id": "CS224V_Lecture_3_>_Chapter_Summaries_>_Questions_for_the_President", "document_type": "chapter summary", "lecture_number": 3, "start_ms": 4957559, "end_ms": 5138035}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 213105 ms - 292399 ms", "content": "Title: CS224V Lecture 3 > Transcript > 213105 ms - 292399 ms\n\nContent: All right, I'm. I'm trying to learn everybody's name, and we're doing a lot of interactions, so let's see how far we can go. I have never had a big class like this. That's the only, you know, where we actually attempt to learn people's names. So. Okay, so let's get started. How's the homework we handed out? Assignment 1. How many people have attempted it? Oh, pretty good. Is it going okay? All right, so let's start this lecture. So this is a third lecture, and we're going to talk about agents. I mean, everybody thinks about nlp. People thinks about assistants and agents. And that is the subject for today's talk. So I want to go back to this beautiful Bloom's taxonomy that we showed. It's really, really helpful. It's got a organization of the various knowledge skills. This is used by educators, and we're using it to organize our work here. And what we're going to focus on are the bottom four layers. So at the bottom is, remember, I don't have to do anything about that because the LLMs", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_213105_ms_-_292399_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 213105, "end_ms": 292399}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 276202 ms - 358803 ms", "content": "Title: CS224V Lecture 3 > Transcript > 276202 ms - 358803 ms\n\nContent: and we're using it to organize our work here. And what we're going to focus on are the bottom four layers. So at the bottom is, remember, I don't have to do anything about that because the LLMs are very good at it. And what we're focusing on are the kinds of things that you do on the web and on your assistants. On the Web, a lot of times you're doing information seeking or you are filling out forms. You know, you book your restaurant, book your hotel, book your flights and get your appointments, all kinds of things like that. Maybe this is better. And also virtual assistants, everybody used Alexa and Siri. And the question here is, in order to do this, in order to provide this as an automated agent, we need the understand, apply, and the analyze and not so much the evaluate and create. Maybe I'm too loud. Is it okay? All right, so what we're going to do today is to follow our plan at beginning the first few lectures is to bring you up to speed as quickly as possible to the state of", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_276202_ms_-_358803_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 276202, "end_ms": 358803}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 342275 ms - 425873 ms", "content": "Title: CS224V Lecture 3 > Transcript > 342275 ms - 425873 ms\n\nContent: Maybe I'm too loud. Is it okay? All right, so what we're going to do today is to follow our plan at beginning the first few lectures is to bring you up to speed as quickly as possible to the state of the art in terms of knowledge and task assistance. And the whole idea is that if I do this, then it will help you think about projects. Right. There are things that you wouldn't know. It is actually very easy to do. And so this is why we are focusing on what it is that we have gotten as opposed to how we get there and how we get there. Maybe I can use a different mic. I don't know. Maybe it's too loud. It has a ring, and it is. It's a little bit different from the other mics I used. So can we get another mic just in case the mic's a problem? So anyways, so the whole idea is to give you the state of the art. I won't be answering all the questions of how you are making these agents happen, because that's a lot of the lectures subsequently. And it is also going to be the topic for the second", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_342275_ms_-_425873_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 342275, "end_ms": 425873}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 413121 ms - 478325 ms", "content": "Title: CS224V Lecture 3 > Transcript > 413121 ms - 478325 ms\n\nContent: of the art. I won't be answering all the questions of how you are making these agents happen, because that's a lot of the lectures subsequently. And it is also going to be the topic for the second assignment. And you will have some intent on experience in building the agents using the tools that we have and that we'll be talking about. Some of you asked me, do I have to use the tools that we are sharing? And the answer is no. You can do whatever you want, but whatever you do, it should be better than the easy things that we can do with our tools. You have a whole quarter for it, but you don't have to use the tools that we are sharing. But we think that it is helpful for a lot of projects. And you will see the landscape of the general assistance. And we're going to overview the technical techniques, the names, the terminology, but not so much the details. So that's the plan for today. So here is the agents at a glance. There are many, many papers, like gazillion papers on how do we", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_413121_ms_-_478325_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 413121, "end_ms": 478325}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 465285 ms - 528274 ms", "content": "Title: CS224V Lecture 3 > Transcript > 465285 ms - 528274 ms\n\nContent: techniques, the names, the terminology, but not so much the details. So that's the plan for today. So here is the agents at a glance. There are many, many papers, like gazillion papers on how do we automate this natural language interface. And at the top I put down information seeking. We separate this short form from the long form. We seen the long form already and that is the Storm and the Coast Storm project. But a lot of the work went on answering questions. Answering questions are actually harder than just curating and summarizing information that it reads on the web, which is what we covered on Storm, because it has to answer the question specifically that you are asking instead of saying, I found these things. You know, this is the kind of thing you see in search engines. I find these things. Let's summarize them. So the short form Q and A is actually not that easy. There are various levels of it. There is free text, okay, I can ask you a question and there are tons of writing", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_465285_ms_-_528274_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 465285, "end_ms": 528274}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 514033 ms - 591177 ms", "content": "Title: CS224V Lecture 3 > Transcript > 514033 ms - 591177 ms\n\nContent: things. Let's summarize them. So the short form Q and A is actually not that easy. There are various levels of it. There is free text, okay, I can ask you a question and there are tons of writing and go get it. And the wiki chat is based on Wikipedia, which is the largest open, largest textual repository there is. Then a lot of information are in databases, so you need to be able to answer questions based on databases. You also have hybrid knowledge bases. Sometimes the information requires you to look up something in the database and the text and mix them. So you have to do multi hop and so forth. So that's difficult. Then beyond databases, there are the knowledge graphs and for example, Wikidata is a knowledge graph. They are not simple tables. It actually is a whole graph and it is actually really complicated to get answers out of them. So that's the information seeking type of Technology. Then if you look at virtual assistants, they are actually performing functions. It's like the", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_514033_ms_-_591177_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 514033, "end_ms": 591177}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 571645 ms - 649017 ms", "content": "Title: CS224V Lecture 3 > Transcript > 571645 ms - 649017 ms\n\nContent: really complicated to get answers out of them. So that's the information seeking type of Technology. Then if you look at virtual assistants, they are actually performing functions. It's like the API calls. There are the simple ones. Alexa and Siri are typically relatively simple. Open the door, turn on the radio, you know, the TV and things like that. What is the weather? Actually the most common, two common functions are what do you think they are? What is the weather? Is one of them. And the other one is what's the time? Okay, it's really trivial. Everybody who's waking up is like, what is the time? So anyway, so usually you see these simple, these are the simple API calls, but you can string them together. Actually the project that we did, it's called Almond, allows you to create things like when it is forecast that rain, that we're going to get rain the next day, turn off the sprinkler. So that's very useful, but that requires a little bit more natural language understanding", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_571645_ms_-_649017_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 571645, "end_ms": 649017}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 632345 ms - 715579 ms", "content": "Title: CS224V Lecture 3 > Transcript > 632345 ms - 715579 ms\n\nContent: things like when it is forecast that rain, that we're going to get rain the next day, turn off the sprinkler. So that's very useful, but that requires a little bit more natural language understanding because we are composing these primitives together. Then beyond that there will be the task oriented agents, that is the. So there's a lot of work on dialogue agents and there's a data set called multiwas that has been used in so many, many papers. And the idea behind that is to be able to understand what is being said. And so if you look at an agent, what it has to do is to read the information and then perform the actions and so forth. Okay, so there is a semantic, so there is the parsing and then there is the action and multiwas. A lot of work goes into using a neural agent policy. But if you look at in real life, you want to control what the agents say and at that point you want to be able to have more of an algorithmic policy. And that is the work next, which is the knowledge and", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_632345_ms_-_715579_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 632345, "end_ms": 715579}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 702599 ms - 774587 ms", "content": "Title: CS224V Lecture 3 > Transcript > 702599 ms - 774587 ms\n\nContent: if you look at in real life, you want to control what the agents say and at that point you want to be able to have more of an algorithmic policy. And that is the work next, which is the knowledge and task. And what we're going to talk about is this project is the project that allows you to have integration of knowledge and tasks. And we're going to apply it, for example to the course assistant. I kind of alluded to it on the first day, but we kind of ran out of time on the details. But that is actually the system for the second homework. And it uses everything that I have labeled lecture three up there. It is really an accumulation of knowledge and tasks together and that's what we're going to do. And just to make sure that you know that there are other non task oriented agents like social agents, chit chat is very common and so forth. And so there are also other works of that level. So chit chat and also you try to persuade people to do things and so forth. And that's more of the", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_702599_ms_-_774587_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 702599, "end_ms": 774587}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 757583 ms - 835133 ms", "content": "Title: CS224V Lecture 3 > Transcript > 757583 ms - 835133 ms\n\nContent: agents, chit chat is very common and so forth. And so there are also other works of that level. So chit chat and also you try to persuade people to do things and so forth. And that's more of the social agents side. And what is interesting is that we discovered that GPT is actually really good with social, with tasks like persuasion. But the problem is that it is not factual. It can start persuading you, coming up with stories that actually didn't, that are actually not true. It's like, oh, you really want to donate to Save the Children. And then suppose you say why? And I say, well, I mean, you know, there is this girl called Mala in Africa, blah blah, blah. It goes on and on, but it is actually not true. Okay, so what we discovered is that you can use GPT to help with the social agents, but what you really still have to worry about is the factuality behind it. So there is, this is the basic form of social bots. Going forward there will be all kinds of things that you want to achieve", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_757583_ms_-_835133_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 757583, "end_ms": 835133}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 822225 ms - 901197 ms", "content": "Title: CS224V Lecture 3 > Transcript > 822225 ms - 901197 ms\n\nContent: but what you really still have to worry about is the factuality behind it. So there is, this is the basic form of social bots. Going forward there will be all kinds of things that you want to achieve that you have to work with, the individuals having it personalized and so forth. That is more of the things that we can explore in the projects, for example. But today we're going to concentrate on just getting you all the basics to get to this point where we can do integrated knowledge and task agents. Okay, Any questions? No? All right, so we're going to start with knowledge and then APIs and then we're going to do knowledge and task oriented agents. So we said that there are free, there's free text. Actually we talked about the free text in the first lecture. Remember we say that when you ask me a question, I'm going to go use search, but I have to filter out things that are irrelevant. I will also use GPT to generate the answer, but we have to split the answers up claim by claim and", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_822225_ms_-_901197_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 822225, "end_ms": 901197}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 885461 ms - 962469 ms", "content": "Title: CS224V Lecture 3 > Transcript > 885461 ms - 962469 ms\n\nContent: ask me a question, I'm going to go use search, but I have to filter out things that are irrelevant. I will also use GPT to generate the answer, but we have to split the answers up claim by claim and then factually check each claim and then you put that together. So that's what we discussed in the first class. Okay, so we have covered free text at the high level. We will talk about the details about how you really make it work in the rest of the lecture. So today we, you know, we're going to focus on the database side. So let's start with databases. And the architecture that we have is that you have information from the outside. We're not pulling out of the LLM memory. And it can be, you know, we talked, you saw how Storm was using Google search. There is Wikipedia free text and there is also data. Wikidata is a knowledge base. It is structured. On top of that you can have private information and you can have documents and knowledge bases and so forth. And we're going to take natural", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_885461_ms_-_962469_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 885461, "end_ms": 962469}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 948709 ms - 1018281 ms", "content": "Title: CS224V Lecture 3 > Transcript > 948709 ms - 1018281 ms\n\nContent: also data. Wikidata is a knowledge base. It is structured. On top of that you can have private information and you can have documents and knowledge bases and so forth. And we're going to take natural language, go through this process called semantic parsing. I'll explain that and it translates into formal queries and you go fetch the data from the external sources. So this is the high level architecture. And SQL, the language that we were using, is the first query language that allows you to express a search that includes information from structured data as well as free text. Okay, you know, you guys familiar with SQL? SQL is all structured. And what do we do with free text? So, you know, we don't have a way of combining them in the past. And that is what the language SQL stand for. All right, so let's start with knowledge bases before we get into the hybrid data structures and so forth. So just what about, you know, why do we care about knowledge bases? There's just lots of", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_948709_ms_-_1018281_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 948709, "end_ms": 1018281}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 1005265 ms - 1077233 ms", "content": "Title: CS224V Lecture 3 > Transcript > 1005265 ms - 1077233 ms\n\nContent: All right, so let's start with knowledge bases before we get into the hybrid data structures and so forth. So just what about, you know, why do we care about knowledge bases? There's just lots of structured data in the world. If you look at what is publicly available. We referred to the wikidata a couple of times. There's this also this thing called schema.org. have you heard of it? No. Have you used it? You have heard of it? What is it? I asked to make an ontology for the first time. So defines a list of literals and definitions and references a bunch of other knowledge bases, like a sentence. Yes. Well, schema.org is intended to be structuring information on the web to start. Okay, so basically, you know, you may not have heard of it, you have used it. Suppose I want to look for the phone number for a restaurant. Typically people put them in the website, right? You can look up the website and you can find it. But Google provides all this information at the top level. They says this,", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_1005265_ms_-_1077233_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 1005265, "end_ms": 1077233}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 1065497 ms - 1135799 ms", "content": "Title: CS224V Lecture 3 > Transcript > 1065497 ms - 1135799 ms\n\nContent: number for a restaurant. Typically people put them in the website, right? You can look up the website and you can find it. But Google provides all this information at the top level. They says this, you know, it gives you on the map the phone number and so forth. Where are they getting this out of? They can scrape every single page to get the web or what happened is that there is an effort to structure the information so that when you create a website, you actually add in a little bit of structured information on your website. That is schema.org that is huge. So you guys have all been benefiting from it. They take all the standard things like opening hours or locations, addresses and so forth. If you take something like ebay, all their product information is actually provided in a structural way via schema.org so it is a gigantic database that is on the public Internet and it's publicly available. So there's tons of information about that. You can see the importance of structured data", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_1065497_ms_-_1135799_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 1065497, "end_ms": 1135799}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 1118783 ms - 1193345 ms", "content": "Title: CS224V Lecture 3 > Transcript > 1118783 ms - 1193345 ms\n\nContent: way via schema.org so it is a gigantic database that is on the public Internet and it's publicly available. So there's tons of information about that. You can see the importance of structured data just by thinking about getting all the phone numbers of every single website. You don't have to deal with the free text when it is structured. You can just pull it out very, very easily for all the locations or organizations that you're interested in. So those are the public databases in private databases. Forbes has an article. Basically they says every company is a data company. Everything from products to corporate information, all the human resources, all the operations. And of course there is personal information. You have calendars, you have email. And you know how when you look for, when you have so much email and then you're always using a search to find your data. So it's kind of a, it's kind of like, it's kind of like a clunky interface when you actually do an email search other", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_1118783_ms_-_1193345_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 1118783, "end_ms": 1193345}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 1178113 ms - 1257755 ms", "content": "Title: CS224V Lecture 3 > Transcript > 1178113 ms - 1257755 ms\n\nContent: you have so much email and then you're always using a search to find your data. So it's kind of a, it's kind of like, it's kind of like a clunky interface when you actually do an email search other than a quick filter. Okay, so for example, you want to specify, they have a little web interface that lets you specify emails from whom or the dates that you want to search in between of and what is in the keyword. And at some point you can actually ask to search for words in the text of the emails, in the body of the email and so forth. So that is both a combination of structured and unstructured data, even among your own email. So just about everything has, there are just lots and lots of databases out there. One idea is that can you take all the databases and just turn them into sentences and use free text analysis over it? That's a sad story if that's what you do. We spend all this time structuring it and there is such an easy way of querying it. It is much better if you natively work", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_1178113_ms_-_1257755_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 1178113, "end_ms": 1257755}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 1244323 ms - 1329813 ms", "content": "Title: CS224V Lecture 3 > Transcript > 1244323 ms - 1329813 ms\n\nContent: use free text analysis over it? That's a sad story if that's what you do. We spend all this time structuring it and there is such an easy way of querying it. It is much better if you natively work with databases. So databases are very interesting because everybody has data, but they all choose to represent the information in just a few styles of databases. And there are just a few query languages. If you know a language, you can query all kinds of databases. Probably everybody here knows about SQL and that is just a standard commercial language for querying information in tables. But there are knowledge bases where things are connected between, by edges between nodes. And there are two common languages, Sparql and not Neo4j. It's Neo4j. And then, then the interesting thing here is that the language is the same, but the domains are actually specified by the database schemas. If you want me to access a new database, just give me the schema and I will be able to do it if I know the data.", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_1244323_ms_-_1329813_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 1244323, "end_ms": 1329813}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 1314645 ms - 1396447 ms", "content": "Title: CS224V Lecture 3 > Transcript > 1314645 ms - 1396447 ms\n\nContent: language is the same, but the domains are actually specified by the database schemas. If you want me to access a new database, just give me the schema and I will be able to do it if I know the data. The query language, this is really powerful, the fact that it is domain agnostic. So and if you look at the queries, they have only a few relational algebraic operations. Okay, so the selection, selection, projection, joined, which is cartesian product, union, set, difference and so forth, it's really a small number of primitives. And then you can extend it with well known operators like sort and aggregate and so forth. The fact that no matter what you want to ask, can be expressed in just a composition of a small number of operations. It's an amazing CS idea. This is what CS is all about. I give you just a small number of primitives and you build everything out of it. You don't ever ask. If I give you a query, it's like, can I express that in that query language? No, that question has", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_1314645_ms_-_1396447_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 1314645, "end_ms": 1396447}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 1385291 ms - 1463727 ms", "content": "Title: CS224V Lecture 3 > Transcript > 1385291 ms - 1463727 ms\n\nContent: I give you just a small number of primitives and you build everything out of it. You don't ever ask. If I give you a query, it's like, can I express that in that query language? No, that question has been solved. Anything that you want to ask about a table is a composition of just those operators. What it means is that if I now want to answer any question against the database, I just have to know how to map it from the natural language to creating simple compositions of these primitives. I can answer any question that you have on databases. It's very expressive, succinct and well defined. So what we are talking about now is that we need to take a natural language that you have and turn it into a formal query in the query language that is accepted by the databases. So for a given domain the problem is as follows. Suppose I say something like, show me the best restaurant in Palo Alto. Do you know how to express this in SQL? How many do? Yeah. What would that look like? I don't know", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_1385291_ms_-_1463727_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 1385291, "end_ms": 1463727}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 1441973 ms - 1527529 ms", "content": "Title: CS224V Lecture 3 > Transcript > 1441973 ms - 1527529 ms\n\nContent: the problem is as follows. Suppose I say something like, show me the best restaurant in Palo Alto. Do you know how to express this in SQL? How many do? Yeah. What would that look like? I don't know exactly, but you would like first search for probably like Japanese restaurants and they group them by location in Palo Alto and then get the max score or something. Yeah. So a very natural sentence that you normally say, you know, oh, I want to go. You tell your friend what is the best restaurant in Palo Alto? They actually have to generate a database query in order to get that answer for you. Okay. And so that's what we need to do so you can have, so you have where you are functioning as a semantic parser. You take the natural language, take its meaning and you turn it into a formal representation. And this is what we call this semantic parser. The parser is translating the natural language into that formal representation. It's semantic because I have to understand what you are saying. It", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_1441973_ms_-_1527529_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 1441973, "end_ms": 1527529}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 1513051 ms - 1590791 ms", "content": "Title: CS224V Lecture 3 > Transcript > 1513051 ms - 1590791 ms\n\nContent: And this is what we call this semantic parser. The parser is translating the natural language into that formal representation. It's semantic because I have to understand what you are saying. It is the meaning that I need to extract and express it in the way the formal languages can handle. Okay. And that is called a semantic parser. And so what we are looking at is that we are building a neuro semantic parser. And in this case this is a very domain specific parser that is for example for restaurant in the restaurant domain. So what you said is roughly what this is, right? You find a restaurant where Japanese is equals to the cuisines that are available and location is equals to Palo Alto and order by rating, which is what best supposed to, you know, is supposed to translate to and Then you sort it, and you sort it in a descending order in limit one. Okay. It's actually extremely precise. What a very casual sentence is very, is actually a very precise database query. And once I get the", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_1513051_ms_-_1590791_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 1513051, "end_ms": 1590791}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 1574835 ms - 1652443 ms", "content": "Title: CS224V Lecture 3 > Transcript > 1574835 ms - 1652443 ms\n\nContent: sort it, and you sort it in a descending order in limit one. Okay. It's actually extremely precise. What a very casual sentence is very, is actually a very precise database query. And once I get the query, I use this to access the database and I get the result. And then I turn this, give the answer to the response generator and it provides something like, oh, I searched for the best Japanese restaurant in Palo Alto and found Daigo. It has a 4.5 rating on our database and offers sushi and Japanese cuisine. Okay, so because you pull out the database entry, you look at the information and you describe it to the user. And this is how we get the basics done for a knowledge agent. Okay? From the natural language to a formal representation, you execute the answer is then turned into nice looking English sentences and we are done. So that's what we are doing for restaurants. But as we said, a query language is domain independent. So what you really would like to do is to say, can we", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_1574835_ms_-_1652443_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 1574835, "end_ms": 1652443}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 1633115 ms - 1713735 ms", "content": "Title: CS224V Lecture 3 > Transcript > 1633115 ms - 1713735 ms\n\nContent: looking English sentences and we are done. So that's what we are doing for restaurants. But as we said, a query language is domain independent. So what you really would like to do is to say, can we generalize to all the domains? So by that we are saying that let's have a neurosylvanic parser that accepts a schema. If you show me a restaurant schema, then I answer restaurant questions. But if you give me a hotel schema, I'll answer hotel question. If you give me chemistry or whatever it is, you just stuff it in there. And so you know, and then you want to have a semantic parser that can give you the formal representation no matter what domain it happens to be. Okay, yes. What is your name? Where's your tag? In addition to just the schema, wouldn't the neural semantic parser also need some information about what the actual information in those certain fields are? The schema has a name, has words, location, address, cuisines for restaurants. It's pretty easy. I just look at it and I can", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_1633115_ms_-_1713735_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 1633115, "end_ms": 1713735}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 1698479 ms - 1772035 ms", "content": "Title: CS224V Lecture 3 > Transcript > 1698479 ms - 1772035 ms\n\nContent: information about what the actual information in those certain fields are? The schema has a name, has words, location, address, cuisines for restaurants. It's pretty easy. I just look at it and I can guess schemas where it just may be very generic like enterprise schemas, which are generally very. So hopefully your name is already mnemonic. Let's put it this way. If you put down A, B, C, D, E, I will fail. Okay, but sometimes you say location, is it the destination or is it the source or whatever it is? So what we normally ask for is that you attach a description associated with each field and then you supply that. And then it just gets better right there. And then if that doesn't work well enough, you give me some examples, okay? And if I see how you use the examples. So this is the few shot, okay? You give me a few shots and I get better. Okay? So but that is the basic idea I'm just keeping it very simple. The details like this we will discuss in the, in the later lectures because", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_1698479_ms_-_1772035_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 1698479, "end_ms": 1772035}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 1757787 ms - 1828479 ms", "content": "Title: CS224V Lecture 3 > Transcript > 1757787 ms - 1828479 ms\n\nContent: shot, okay? You give me a few shots and I get better. Okay? So but that is the basic idea I'm just keeping it very simple. The details like this we will discuss in the, in the later lectures because I, right now I just want to give you the high level picture. Okay? So just apply the schema and you get an agent. That's pretty cool, right? So this is what we're going after is like if you want to build a, an agent that answers questions that have databases, this is how you're going to do it. So the first round of this is that you do a zero shot prompt with LLMs, such as you are a semantic parser. It actually understands what that is. Generate a query for a restaurant database with the following signature and you say it is an SQL database and it will give you the SQL SQL query for. And it works for simple tables, simple queries right off the bat. Because GPT actually already knows the SQL syntax. Okay. And we're gonna talk about how we handle more complicated cases in the future. All", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_1757787_ms_-_1828479_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 1757787, "end_ms": 1828479}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 1813615 ms - 1889547 ms", "content": "Title: CS224V Lecture 3 > Transcript > 1813615 ms - 1889547 ms\n\nContent: works for simple tables, simple queries right off the bat. Because GPT actually already knows the SQL syntax. Okay. And we're gonna talk about how we handle more complicated cases in the future. All right? So for example, I just wanna show you this in action. Here is a restaurant assistant. And if you say so, this is for example, the database. So let's look at this conversation. My dad is visiting me in Mountain View. What do you think about dinner choices? Okay. Very casual, natural language. And it translates into this. You're selecting from a restaurant where location is equal to Mountain View. Very straightforward. And you get the answer that we show here. How about Italian instead? I really like the food there. When I visited Florence last year, the generated SQL query adds the fact that you're looking for Italian restaurant and it actually retains the information that the location is Mountain View. Okay, so this is really important. I'm showing you what it means to be in a", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_1813615_ms_-_1889547_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 1813615, "end_ms": 1889547}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 1879051 ms - 1946131 ms", "content": "Title: CS224V Lecture 3 > Transcript > 1879051 ms - 1946131 ms\n\nContent: fact that you're looking for Italian restaurant and it actually retains the information that the location is Mountain View. Okay, so this is really important. I'm showing you what it means to be in a conversation. You have to understand what has gone on and information from previous turns. It has to be transferred and applied to the current term. And then in this particular case it's like, oh, what is the ham called in Italian? His prosciutto. And in this case we are not actually calling the database. You may actually use the GPT to answer questions like that. Then later on he says, thanks, we'll be visiting Stanford. How about in Palo Alto? It's not even a full sentence. How about Palo Alto? Okay, now you have to understand that we are changing from Mountain View to Palo Alto. Okay, so this is what the semantic parser needs to do in a conversation. You have to retain the context. So that's a very quick interview, quick overview of the databases. Let's talk about something harder. So", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_1879051_ms_-_1946131_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 1879051, "end_ms": 1946131}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 1931299 ms - 2011201 ms", "content": "Title: CS224V Lecture 3 > Transcript > 1931299 ms - 2011201 ms\n\nContent: is what the semantic parser needs to do in a conversation. You have to retain the context. So that's a very quick interview, quick overview of the databases. Let's talk about something harder. So let's talk about Wikidata. Wikidata is the largest live Knowledge graph. It is being updated all the time today. It has 15 billion triples. That connects two nodes with a property. It has over 100 million entities, 10,000 properties, 25,000 human contributors to this graph. It's huge. And you may not know about Wikidata. You have heard of Wikipedia for sure. And every Wikipedia article has a corresponding entry in Wikidata and not vice versa. Okay, Wikidata is much, much bigger and you may not be using it yourself, but it is actually used in research, for example, life sciences, digital humanity and so forth. It has everything about where every city is in the world, how many people there are in each city and what are the, you know, just all kinds of information are in this wikidata and the", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_1931299_ms_-_2011201_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 1931299, "end_ms": 2011201}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 1995339 ms - 2076500 ms", "content": "Title: CS224V Lecture 3 > Transcript > 1995339 ms - 2076500 ms\n\nContent: and so forth. It has everything about where every city is in the world, how many people there are in each city and what are the, you know, just all kinds of information are in this wikidata and the representation, they are not a table. Why? Because we're talking about everything from people to places to drugs to medicine to physics to whatever it is. There are just many, many, many different forms of kinds of information. And things are actually represented in a graph. And the query is with sparkle. The query language is sparql. Give you an example of what it means to write in sparql. Suppose I say who founded Stanford? Of course Stanford. But. So this is the query that you have to use. You say select X where WDQ 41506 WDT P112 question mark X. That's the query you have to write. Why? Yeah, really. You know, you are asking me about the property name. What if the name is not well understood? You get a number. You get numbers for it. The reason why you have to have numbers is that there", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_1995339_ms_-_2076500_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 1995339, "end_ms": 2076500}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 2064572 ms - 2136091 ms", "content": "Title: CS224V Lecture 3 > Transcript > 2064572 ms - 2136091 ms\n\nContent: really. You know, you are asking me about the property name. What if the name is not well understood? You get a number. You get numbers for it. The reason why you have to have numbers is that there are unique identities. Do you know how many Stanfords there are? There is the university, the person, the garage, the swim school. There are tons of Stanfords out there, exactly the same name. There are still many of them out there. You have to have a unique ID. There are 100 million entities. That means 100 million numbers here. And then the properties have to be precise. And also that's a property. The property is actually not as difficult. It's a simple one to one. The words, they are very precise. But anyways, this is what you have to write. And it is so hard that there are. If you look at Wiki, if you go on the Wikidata website, they actually have forums where the experts will get together to describe how you can create a query that does xyz. I was giving you a tiniest example. Let's", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_2064572_ms_-_2136091_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 2064572, "end_ms": 2136091}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 2121219 ms - 2195937 ms", "content": "Title: CS224V Lecture 3 > Transcript > 2121219 ms - 2195937 ms\n\nContent: Wiki, if you go on the Wikidata website, they actually have forums where the experts will get together to describe how you can create a query that does xyz. I was giving you a tiniest example. Let's talk about something a little bit more interesting. Suppose you say who are the doctoral advisors of Leonard Euler and their advisors and so on. In addition, who are his doctoral, Doctoral student, grand student, great grand student, blah blah, blah blah. Each tuple and the result should contain both the student and the doctoral advisor. Okay, you know what it is, right? I'm just trying to figure out all the relationships between advisor and advisee. But now you have to express it in sparkle and that is the sparkle that you have. You're supposed to write not easy. Okay, I don't, I'm not going to try to explain this either. So what do we do? So clearly, if I can just say that it is much easier than trying to write that and can we get AI to help? This is the title, this is the topic of a", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_2121219_ms_-_2195937_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 2121219, "end_ms": 2195937}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 2176697 ms - 2255653 ms", "content": "Title: CS224V Lecture 3 > Transcript > 2176697 ms - 2255653 ms\n\nContent: to try to explain this either. So what do we do? So clearly, if I can just say that it is much easier than trying to write that and can we get AI to help? This is the title, this is the topic of a paper that I wrote with my students and it just got accepted into MNLP this year. And it is a sparkle based information navigation for challenging real world questions. We work with Harold who is from Wikimedia Foundation. He showed us the forum and we picked out the hard questions and we say, let's try to automate that. And it took us a while and the end is that we have created what we call an agentic approach. We are trying to imitate the expert workers. This is a story from the beginning till now. We are just trying to automate what humans do. You know, like the wiki chat, it's what humans do. When I do Storm, it's what the humans do, okay? We search and then we organize and write outlines and so forth. And we do the same thing. We emulate what the humans do. We first of all learn how to", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_2176697_ms_-_2255653_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 2176697, "end_ms": 2255653}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 2244085 ms - 2312891 ms", "content": "Title: CS224V Lecture 3 > Transcript > 2244085 ms - 2312891 ms\n\nContent: When I do Storm, it's what the humans do, okay? We search and then we organize and write outlines and so forth. And we do the same thing. We emulate what the humans do. We first of all learn how to do it and then we just teach it. So what we do here is that you look at the question, you may try out a simpler query. For example, you try to run it, you look at the answer and then you say, oh, this is no wrong. And then you have to guess what it is or figure out what it is, try different experiments, you rewrite it and you run it again. So this is a process that we know how to do. We can actually also get the LLM system to do. And the way to do it is to call the LLM multiple times, which is the whole concept of a software control over LLM calls. And it actually does the work for you instead of you doing it yourself. So, oh, I don't have the results here. We'll talk about it in the, in subsequent lectures. But this problem is kind of solved in the way that the results are, are kind of", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_2244085_ms_-_2312891_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 2244085, "end_ms": 2312891}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 2294751 ms - 2382547 ms", "content": "Title: CS224V Lecture 3 > Transcript > 2294751 ms - 2382547 ms\n\nContent: of you doing it yourself. So, oh, I don't have the results here. We'll talk about it in the, in subsequent lectures. But this problem is kind of solved in the way that the results are, are kind of like, are very useful. And the cool part here is that we have released it with the Wikidata folks in July just Two months ago, and it is now live on Spinach GD Stanford Edu. And people are actually using it on the public website. So that's the knowledge graph. Now we talk about hybrid data. Okay, A question I have for the those like, complicated queries. How do we guarantee sort of like completeness or like maybe like we miss one or two facts? So very good question. We will talk about it again in a lot of detail. The first thing you do is that whatever you do, you have to describe what it is that you have done. What question are you trying to query and what is the answer? Don't just give the answer. First of all, you have to be transparent. I did this. Here is the answer. And the answer is", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_2294751_ms_-_2382547_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 2294751, "end_ms": 2382547}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 2366999 ms - 2437005 ms", "content": "Title: CS224V Lecture 3 > Transcript > 2366999 ms - 2437005 ms\n\nContent: you have done. What question are you trying to query and what is the answer? Don't just give the answer. First of all, you have to be transparent. I did this. Here is the answer. And the answer is correct. If I did the right thing, but I don't know if I did the right thing. But I told you what I did. So once I give this to you, then the user can come back and say, that's not what I wanted. And you do the corrections. Okay? So that's the basic principle. For things that are really hard, we can't. So for example, for the Q and A, we try to get to the 98%, but for something like this, it is hard even for the humans and there's a lot of ambiguity. And if, you know, as we will talk about it, that graph is a gigantic mess. Okay? So even the humans have to discuss how to get it done. And so we just have to be in the conversation. We always involve the user, but you have to be transparent and let them validate what you are, you know, what you are doing, verify what you are doing. Good", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_2366999_ms_-_2437005_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 2366999, "end_ms": 2437005}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 2423171 ms - 2500335 ms", "content": "Title: CS224V Lecture 3 > Transcript > 2423171 ms - 2500335 ms\n\nContent: so we just have to be in the conversation. We always involve the user, but you have to be transparent and let them validate what you are, you know, what you are doing, verify what you are doing. Good question. So now let's talk about hybrid data. So for everything that we do almost, there is some free text associated with it. For example, if you take something simple like restaurants, oh, this is a very funny example. We did this work and we got it working with the databases. I run into my colleague and I say, try this. Try my restaurant chatbot. And my colleague, the first thing he said is, I want to find a spicy Chinese restaurant. I was like, spicy? Where do I find spicy? Where the spicy goes into the reviews. You don't find it in the structured data. Okay? And right there I say, oh, my God, I thought it is something very, very structured even that I need to find things in the reviews. Okay? So of course, restaurants, tons of things are in reviews. And you know how you search for", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_2423171_ms_-_2500335_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 2423171, "end_ms": 2500335}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 2486831 ms - 2549675 ms", "content": "Title: CS224V Lecture 3 > Transcript > 2486831 ms - 2549675 ms\n\nContent: my God, I thought it is something very, very structured even that I need to find things in the reviews. Okay? So of course, restaurants, tons of things are in reviews. And you know how you search for restaurants? You search for restaurants and then you see some. And then you say, okay, let me read some reviews. You cannot read them all, but you kind of look at a Few. But the whole concept here is that you really want to combine the two. Okay, we know how to do free text search. I talked about it like the wiki chat and we just talked about structure. Now we have to combine them. And that is true of other products where I have reviews, where we look at courses, you want to look at reviews and so forth. So if I look at medical data, there are the structured information, but then there is a discussion, for example, on the history and diagnosis and stuff like that. There's tons of information that are really needed, that are available. And in both you need both forms of information. So", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_2486831_ms_-_2549675_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 2486831, "end_ms": 2549675}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 2533693 ms - 2615701 ms", "content": "Title: CS224V Lecture 3 > Transcript > 2533693 ms - 2615701 ms\n\nContent: a discussion, for example, on the history and diagnosis and stuff like that. There's tons of information that are really needed, that are available. And in both you need both forms of information. So what do we do? So we came up with this really interesting and simple idea and we say, look, we have SQL already. We're not going to abandon the wonderful expressiveness of query languages when it comes to databases. Okay, so I re retained that. But for the free text, what do we usually do? We usually get a summary or we ask for an answer. So these are the two primitives. Let's fold them together. So suppose I want to say I want a family friendly restaurant in Palo Alto. The semantic parser will put it into. This is the S uQL. We have only added two functions. You know, SQL allows you to extend it with functions. So we just extended with two functions. Summary function and the answer function. So for example, you're asking for a family friendly restaurant. I am going to take this question", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_2533693_ms_-_2615701_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 2533693, "end_ms": 2615701}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 2600317 ms - 2671787 ms", "content": "Title: CS224V Lecture 3 > Transcript > 2600317 ms - 2671787 ms\n\nContent: it with functions. So we just extended with two functions. Summary function and the answer function. So for example, you're asking for a family friendly restaurant. I am going to take this question and ask it from the reviews. Okay, I know the reviews have the free text in it, so I'm going to call my free text Q and A routine with this question and I get the answer. So I hear we say, is it a family friendly restaurant? Even want it to be? Yes. And at the end, after I look it up, then I actually want to have a good summary. Then I would say, oh, give me a good summary of the reviews. So this is why when I showed you earlier the reviews, I mean the answers or the description of the restaurants are more interesting than just say Daigo. I actually know something about it because we actually look at the reviews. So this is the combination. It's a very simple combination. But the key is that these are two functions. You can use the functions anywhere. The summary can exist here or you can", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_2600317_ms_-_2671787_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 2600317, "end_ms": 2671787}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 2659451 ms - 2739919 ms", "content": "Title: CS224V Lecture 3 > Transcript > 2659451 ms - 2739919 ms\n\nContent: look at the reviews. So this is the combination. It's a very simple combination. But the key is that these are two functions. You can use the functions anywhere. The summary can exist here or you can do different parts. Basically everything is compositional. You can compose a function, you find a result and then you look up a free text field for that, for that particular record and so forth. So it composes. Don't worry if you think that you don't quite get it all because we're going to talk about it. Later. Okay, so this is just very, very simple set of primitives. And now you can sees the improvement here. Okay, so here's my colleague's question. I like some spicy Sichuan food in Palo Alto. Can you help? So that is the query that we generate. And we ask for, you know the restaurant in Palo Alto, it is Sichuan's cuisine. And we ask, ask, among all the reviews, do we know if this restaurant serves spicy food? Okay. And in this case the answer is, I search for restaurants that serve", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_2659451_ms_-_2739919_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 2659451, "end_ms": 2739919}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 2721393 ms - 2801535 ms", "content": "Title: CS224V Lecture 3 > Transcript > 2721393 ms - 2801535 ms\n\nContent: Palo Alto, it is Sichuan's cuisine. And we ask, ask, among all the reviews, do we know if this restaurant serves spicy food? Okay. And in this case the answer is, I search for restaurants that serve spicy Sichuan food in Palo Alto. I found taste and they describe it and taste. How many people know taste? It is a really spicy Chinese restaurant and it's actually also very good. Daigo is also a very good Japanese restaurant. Okay. And they actually kind of, kind of like pass the test, I would say. And so it has a good description and then it says, the user says, that sounds delicious. Would my friend who does not like spicy food like it too? Very natural English. Okay, I'm not talking to a bot. Okay, this is how you talk to people, right? Normally. And it translates it into the following sentence. So we are asking about the restaurant taste in Palo Alto. And we ask, does this restaurant have non spicy options? Okay, so the English doesn't exactly say does it have non spicy option, But", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_2721393_ms_-_2801535_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 2721393, "end_ms": 2801535}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 2785935 ms - 2855459 ms", "content": "Title: CS224V Lecture 3 > Transcript > 2785935 ms - 2855459 ms\n\nContent: So we are asking about the restaurant taste in Palo Alto. And we ask, does this restaurant have non spicy options? Okay, so the English doesn't exactly say does it have non spicy option, But GPT is able to phrase it in a way that matches the kind of things you can find in reviews. Okay. No, it doesn't ask about your friend, for example. Okay. It just goes ahead and rephrase it in a way that searches the information from the text. And the answer is very interesting. It says, I searched for information about taste in Palo Alto. According to reviews, taste offers non spicy options such as broccoli with beef and stir fry Chinese greens with garlic. So your friend who does not like spicy food should be able to find something they enjoy as well. Okay, so this is very, very different from the kind of call. I don't know how many of you have worked with call agents on the phone when you try to book anything and stuff like, they don't talk like this. Okay, so this is really getting to the point", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_2785935_ms_-_2855459_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 2785935, "end_ms": 2855459}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 2841347 ms - 2912567 ms", "content": "Title: CS224V Lecture 3 > Transcript > 2841347 ms - 2912567 ms\n\nContent: of call. I don't know how many of you have worked with call agents on the phone when you try to book anything and stuff like, they don't talk like this. Okay, so this is really getting to the point where it is offering an interesting conversation for you to have. Okay. You can talk about many different things. So in the evaluation we showed that if you use SQL. Oh, first of all, we found that when we did a study, we just asked people to ask questions. 55 out of 100 actually needed structured and unstructured data. Okay. So this is very, very common. And this is all just about restaurants and linearization are the old techniques where they take all the databases and Turn them into English and then you just do the free text search. And we show that we are just a lot better because we can take advantage of what is in the databases. This is interesting because I have friends, I have colleagues who keep asking me, it's like, why do you need work with databases? Just turn them all into", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_2841347_ms_-_2912567_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 2841347, "end_ms": 2912567}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 2902671 ms - 2969473 ms", "content": "Title: CS224V Lecture 3 > Transcript > 2902671 ms - 2969473 ms\n\nContent: take advantage of what is in the databases. This is interesting because I have friends, I have colleagues who keep asking me, it's like, why do you need work with databases? Just turn them all into text. And I think that's such a waste of effort. Okay. And so this kind of shows you, this is really good to be able to work with the data in their native form, whether they are databases or free text. So this is available and you can go and talk about restaurants in the Bay Area on our website. So that's the knowledge assistance. So the things to take away, the high level things that you should remember is that the data can be accessed via data in databases, can be accessed via query languages. What we're trying to do is to use a neural model to semantically parse natural language into formal queries so that we can execute them. And if you parameterize with respect to the schema, then you can have a single semantic parser. And it works with different databases. It's domain independent Q", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_2902671_ms_-_2969473_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 2902671, "end_ms": 2969473}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 2956697 ms - 3031821 ms", "content": "Title: CS224V Lecture 3 > Transcript > 2956697 ms - 3031821 ms\n\nContent: queries so that we can execute them. And if you parameterize with respect to the schema, then you can have a single semantic parser. And it works with different databases. It's domain independent Q and A against databases. All right. It's very powerful. Let's talk about API calls. So this kind of. Suppose I want to have a enrollment API that says if you want to enroll, you need to get the student id, course name, grade type, number of units, and the natural language like this comes in and you want to generate that API. And here again we, of course, we're using a neural semantic parser. Just like before, we want it to be independent of the task at hand. So we take the signature of the API. It's kind of like the schema of the database and we supply that to this generic neurosmantic parser. And you will generate the natural language into that formal call, API call. And now you take the call, you execute it, you get the result, and you get back the response. Okay, now we're. That's the", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_2956697_ms_-_3031821_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 2956697, "end_ms": 3031821}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 3018223 ms - 3090761 ms", "content": "Title: CS224V Lecture 3 > Transcript > 3018223 ms - 3090761 ms\n\nContent: And you will generate the natural language into that formal call, API call. And now you take the call, you execute it, you get the result, and you get back the response. Okay, now we're. That's the basics of API calls. Any question about that? Yeah. Where's your name? I don't know. Why don't you have a name? Okay, somebody can give him a piece of paper before you go. Everybody gets a name in the next class. I want a name. Okay, bring the name back. All right, what's your question? Is this the same thing as like function calling or tool calling? This is function calling. So you're not building the semantic parts yourself, you're just using the one that's provided by the LLMs API, right? I'm not. I want to go way beyond that, so you can use. People are doing function calling and it has, it's. It you can just get. It is a little bit more tuned than a generic LLM. It's the same idea. Yeah, that is function calling, but we're going to go beyond that. All right, so for example, I'm not", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_3018223_ms_-_3090761_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 3018223, "end_ms": 3090761}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 3071055 ms - 3153433 ms", "content": "Title: CS224V Lecture 3 > Transcript > 3071055 ms - 3153433 ms\n\nContent: it's. It you can just get. It is a little bit more tuned than a generic LLM. It's the same idea. Yeah, that is function calling, but we're going to go beyond that. All right, so for example, I'm not interested in a single API. I really actually want to chain things together and so forth. But anyways, this is called function calling and you can use those functions for those, those tools for simple things. And it works. Okay, so you supply the signature again and get a translator. But normally maybe this is the beginning of when things are a little bit different. Is like if I just say I want to enroll in a course, you will have to ask me for the missing argument. So you need a conversation. So this is standard. It is called slot filling. And then if I want to, before I enroll you, I better ask for confirmation because unlike queries, I can give you an answer that you did not ask for, but you want to be. When I actually transfer money between your banking accounts and so forth, I need to", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_3071055_ms_-_3153433_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 3071055, "end_ms": 3153433}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 3141385 ms - 3206413 ms", "content": "Title: CS224V Lecture 3 > Transcript > 3141385 ms - 3206413 ms\n\nContent: for confirmation because unlike queries, I can give you an answer that you did not ask for, but you want to be. When I actually transfer money between your banking accounts and so forth, I need to get confirmations. So this is the kind of conversation that you would get. You would expect. It's like I like to enroll in a course. It says that, oh, I need a parameter. What is your student id? I asked you for it. What course would you like to enroll in? Would you like to take it with a grade, with how many units? And then at the end we ask for the confirmation and to make sure that this is what you want. So this is the standard little conversation template. Okay, so that's the basic idea behind the API signatures. And we're looking for the signature parameterized semantic parsing that translates natural language to QL for a given set of API signatures. Everybody's clear on this, right? Everything's good. All right, so let's talk about knowledge plus task oriented agents. So we talked", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_3141385_ms_-_3206413_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 3141385, "end_ms": 3206413}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 3192885 ms - 3266671 ms", "content": "Title: CS224V Lecture 3 > Transcript > 3192885 ms - 3266671 ms\n\nContent: natural language to QL for a given set of API signatures. Everybody's clear on this, right? Everything's good. All right, so let's talk about knowledge plus task oriented agents. So we talked about knowledge, we talked about simple tasks. Let's talk about the whole thing. Let's talk about a motivation as a case starts with a case study. So enrolling in a course, you can think of as a task agent booking a restaurant. These are APIs. They get harder and harder, but these are APIs. But in reality, as I help you with these things, I said, what restaurant do you want to book? And you say, oh, I want a spicy restaurant. I don't have a restaurant name. So I started asking you for the question to help me answer the questions that you asked me for. Okay, so the concept is like just about any task can imagine if I want to Help you with purchasing, ordering food and so forth. You're going to ask me, oh, does this have, does it have peanuts or whatever? Okay, so there are a lot of times tasks", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_3192885_ms_-_3266671_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 3192885, "end_ms": 3266671}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 3253863 ms - 3325687 ms", "content": "Title: CS224V Lecture 3 > Transcript > 3253863 ms - 3325687 ms\n\nContent: can imagine if I want to Help you with purchasing, ordering food and so forth. You're going to ask me, oh, does this have, does it have peanuts or whatever? Okay, so there are a lot of times tasks cannot be just done by asking you for the parameters in a function call. Okay, so this is when it kind of goes beyond mapping to a simple API call in a conversational agent. So if I want to help you fill out taxes, you're going to say, what's a deduction? What qualifies for it? There are so many questions typically when you do any of these things. And that's why we are very keen on having a task and knowledge oriented agent. And I think our paper is like the first one that actually deals with this properly. So let's talk about a case study at course enrollment. We have a lot of CS master students here and you guys have seen this thing, right? So this is the course requirement for AI, course requirement for computational biology and so forth. There are many, many pieces of paper out there and", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_3253863_ms_-_3325687_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 3253863, "end_ms": 3325687}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 3309991 ms - 3377475 ms", "content": "Title: CS224V Lecture 3 > Transcript > 3309991 ms - 3377475 ms\n\nContent: here and you guys have seen this thing, right? So this is the course requirement for AI, course requirement for computational biology and so forth. There are many, many pieces of paper out there and the question here is like, what course would you like to enroll? And most people would consult this and say, what do I need in order to graduate? And so this is part of the information that you want to know. So for example, if you. I gave you a very simple example right Earlier. What course would you like? 224V with units. I just give you the answers. But in real life this is an example of a question or answer that you can get. What course would you like to understand? I'm studying computer science. I want to complete the significant information requirement. You guys know about that, right? What are some of the options that require the least amount of work? Right. I don't know. Have you asked that question before? I can tell you that there are lots of students who did. And the answer is", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_3309991_ms_-_3377475_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 3309991, "end_ms": 3377475}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 3364135 ms - 3433047 ms", "content": "Title: CS224V Lecture 3 > Transcript > 3364135 ms - 3433047 ms\n\nContent: What are some of the options that require the least amount of work? Right. I don't know. Have you asked that question before? I can tell you that there are lots of students who did. And the answer is how am I going to. How does the agent answer the question? Okay, in order to answer the question I need to consult the degree requirements. I have to look at the bulletin when it is offered. I have to look at Carter. Where are the ratings and reviews? Right? You want to know the least amount of work. It's not in the bulletin. Okay, you're hoping that somebody have put it into the reviews, right? Or descriptions and. Oh, actually in Carter there is this thing about hours of work. That's what you want to look up. All right, so in order to answer the question, first of all you have to look at the requirement. Then it says which courses have the implementation. Satisfy the implementation requirement. There's a whole bunch of them, none of them easy. Okay. There's a whole Bunch of them. And", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_3364135_ms_-_3433047_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 3364135, "end_ms": 3433047}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 3416079 ms - 3491161 ms", "content": "Title: CS224V Lecture 3 > Transcript > 3416079 ms - 3491161 ms\n\nContent: the requirement. Then it says which courses have the implementation. Satisfy the implementation requirement. There's a whole bunch of them, none of them easy. Okay. There's a whole Bunch of them. And for each one, now you have to look it up. Okay, you pick up 140, the first one. Then you look up the course, and then you say, okay, I need to find out how the intensity of the course. All right, I got the first one. Now let me look at the second course and then look at the requirement, the third course and the requirement. I mean the hours, I mean, not the requirement. And I'm looking up the intensity. So now I have to check out every single course that satisfies the implementation requirement. And then you pick the one that has the least amount of work. That's a lot of work. I don't know if you have done this before. Yeah. Okay, now wouldn't it be nice if you can just ask an agent that. Yeah, it goes on. So that's what we need to create, is an agent that can help you enroll, but at the", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_3416079_ms_-_3491161_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 3416079, "end_ms": 3491161}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 3473625 ms - 3548587 ms", "content": "Title: CS224V Lecture 3 > Transcript > 3473625 ms - 3548587 ms\n\nContent: you have done this before. Yeah. Okay, now wouldn't it be nice if you can just ask an agent that. Yeah, it goes on. So that's what we need to create, is an agent that can help you enroll, but at the same time answer all the questions that you may have from all the databases. Sometimes it is structured, sometimes it is unstructured. So this is what you have to do in order to make this agent happen. You first of all create a form. So, for example, you say you want to do enrollment. You have to know who the student is, which is the name, the id, email address, you want to make sure it's the right person. Then you say, what is the course? The course has the same four things that we talk about. The course name, the grade, type, number of units. And in the end, I want to be able to make sure that the. Because I want to say you have to ask the user before you call. So we have also the variable confirm to set to confirm, and that describes your entire task. The task itself seems simple. The", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_3473625_ms_-_3548587_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 3473625, "end_ms": 3548587}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 3529735 ms - 3609371 ms", "content": "Title: CS224V Lecture 3 > Transcript > 3529735 ms - 3609371 ms\n\nContent: the. Because I want to say you have to ask the user before you call. So we have also the variable confirm to set to confirm, and that describes your entire task. The task itself seems simple. The hard thing is the integration with the knowledge. What do we do with the knowledge? You just have to give me the databases, which is what we just described. You give me the schemas. Okay. You declare that there are in the offerings, it's the days, the start time, end time, instruction names and so forth. You just write them down is in the. For each database, you write down the schema and you give it to the agent and you're done. All right? So this is about the least amount of work that anybody can do to achieve the goal of an agent that does tasks and knowledge, because none of this information can be skipped. And that's all you have to do. And we give you an agent. Pretty cool. Yeah. So what does it do? So, for example, this question that you asked earlier is going to translate into this SQL", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_3529735_ms_-_3609371_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 3529735, "end_ms": 3609371}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 3592613 ms - 3674255 ms", "content": "Title: CS224V Lecture 3 > Transcript > 3592613 ms - 3674255 ms\n\nContent: be skipped. And that's all you have to do. And we give you an agent. Pretty cool. Yeah. So what does it do? So, for example, this question that you asked earlier is going to translate into this SQL sentence. Okay? So you select the Title, course codes, description, average hours spent. So you first of all search among the courses database where the significant implementation requirement is equals to yes. And then you order by the average hours spent. Okay? And you take the top five here and I am going to tell you what the title, course codes, description and average hours spent. So that long thing that it would take me a while to do, you just, just give it to the agent and it will give you the perfect answer. And you don't know. And the person who's asking this question has no clue what all the schemas are. They just ask the questions. So I think it is interesting to look at this example of the interaction. I mean, we are not talking about just theory. This is all things that work.", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_3592613_ms_-_3674255_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 3592613, "end_ms": 3674255}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 3657727 ms - 3731979 ms", "content": "Title: CS224V Lecture 3 > Transcript > 3657727 ms - 3731979 ms\n\nContent: all the schemas are. They just ask the questions. So I think it is interesting to look at this example of the interaction. I mean, we are not talking about just theory. This is all things that work. Okay? This is a working system. You say, I want to come complete the significant implementation requirement. So the assistant says, I found these courses and they're all the right courses. And at the end the agent says, oh, what is the course that you want to take? Remember, the agent goal is not just to answer questions, they actually want to enroll you. So this is not the same as a Q and A system knowledge assistant. It actually has. It wants to complete a task. This is the task I want you to tell me what other. What do you want to take? And you say, great, oh, not so fast. You know, when are these courses offered? Then we look up another set of table and you say, look here, they are offered here. Okay, which course are you going to take? I want to answer. I ask you this question and", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_3657727_ms_-_3731979_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 3657727, "end_ms": 3731979}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 3718083 ms - 3789127 ms", "content": "Title: CS224V Lecture 3 > Transcript > 3718083 ms - 3789127 ms\n\nContent: are these courses offered? Then we look up another set of table and you say, look here, they are offered here. Okay, which course are you going to take? I want to answer. I ask you this question and then the user says, oh, can you sort them based on rating? I was like, sure, I sort them. You find the one that is highly rated and you may say, oh, I want to take the top rated one. Okay? And the assistant says, great choice. Now I have the course that you want. It's the computer graphics and imaging. Could you please specify the desired grading basis? Credit, no credit or letter. Instead of saying credit or no credit or letter, you say, oh my goodness, I need to figure out if I want it for credit. I want to know how many hours I need to spend on it. But you know that most of the calling agents you see in commercial world, they ask you a question, you have to answer the question. You ask another question in the middle of a conversation. So it has to switch over. It is expecting, I'm", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_3718083_ms_-_3789127_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 3718083, "end_ms": 3789127}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 3775227 ms - 3846907 ms", "content": "Title: CS224V Lecture 3 > Transcript > 3775227 ms - 3846907 ms\n\nContent: agents you see in commercial world, they ask you a question, you have to answer the question. You ask another question in the middle of a conversation. So it has to switch over. It is expecting, I'm trying to parse, I'm expecting that you give me the number, I mean the options. But you say something else. I have to deal with that. What the user says, get higher priorities. So we're going to. So this Is the user has its initiative, as opposed to the agent having the initiative of trying to complete the course enrollment. So the user comes first. So therefore the agent says, on average, you have to spend about that many number of hours. I answer it and then it goes back and asks you, what is the grading basis that you want? So you see, it goes back and forth and then at this point you say, okay, I will take it for the letter grade. What's the maximum units I can tick it for? And then it goes on. Okay, I give you the units. And then they say, oh, I want it before, and so forth. So this", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_3775227_ms_-_3846907_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 3775227, "end_ms": 3846907}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 3836555 ms - 3900489 ms", "content": "Title: CS224V Lecture 3 > Transcript > 3836555 ms - 3900489 ms\n\nContent: okay, I will take it for the letter grade. What's the maximum units I can tick it for? And then it goes on. Okay, I give you the units. And then they say, oh, I want it before, and so forth. So this is a very dynamic conversation. Nobody scripts what the agent is going to say at any one point. I just give you a form that you're supposed to fill. And depending on what the user has been saying, you say different things and the user can give you the information in a different order. From the beginning, the user can call and say, I want to take a four unit course and this is the number. So the parser takes the information and run with it. You don't just say, oh, which course would you like? What number do you want? What number of units? It has to be very responsive. It has to listen to what you have said. We put the information into the table whenever you say it, and we ask you for information only if it is missing from that table. Okay, so it's not the same as the good old boring ask you", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_3836555_ms_-_3900489_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 3836555, "end_ms": 3900489}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 3885573 ms - 3967381 ms", "content": "Title: CS224V Lecture 3 > Transcript > 3885573 ms - 3967381 ms\n\nContent: have said. We put the information into the table whenever you say it, and we ask you for information only if it is missing from that table. Okay, so it's not the same as the good old boring ask you question 1, 2, 3, 4, 5, and fill it in slot by slot. So what we're seeing here is that there are many possible dialogues, and even for a task with only a few parameters, as in this case, we have to take care of the users first and we have to take care of the agents. So here is yet another example, just to drill that into your head. So, for example, how much money do you wish to transfer? If the banker asks you, and at that point you say, how much money do I have in my account before I can tell you how much money to transfer? Very natural. But this will kill most. Most agents today. They want a number, they expect a number. Okay? So that's the complexity of the agent that we want to be able to get to. How do we build it? So first of all, let's talk about the design of the system of this", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_3885573_ms_-_3967381_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 3885573, "end_ms": 3967381}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 3945373 ms - 4029235 ms", "content": "Title: CS224V Lecture 3 > Transcript > 3945373 ms - 4029235 ms\n\nContent: a number, they expect a number. Okay? So that's the complexity of the agent that we want to be able to get to. How do we build it? So first of all, let's talk about the design of the system of this worksheet. So the concept here is that you write down the task, you write down the knowledge, and then you give it to the agent. And the agent has three parts. The first one is a semantic parser. It needs to listen to you. And I formally describe what you just said like before. So you give me a sheet. It has all these questions, the information. Whenever I can, I fill in the variables using the semantic parser. It has to be contextual. Contextual means that it has to remember the context of that utterance, which is the history of the dialogue so far. Then I hear what you say, I decide on the agent policy, what do I do and then I generate a response and the agent policy. The key things come from the user, how you're supposed to handles handle the pieces of information. And if the user talks", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_3945373_ms_-_4029235_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 3945373, "end_ms": 4029235}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 4013029 ms - 4087113 ms", "content": "Title: CS224V Lecture 3 > Transcript > 4013029 ms - 4087113 ms\n\nContent: policy, what do I do and then I generate a response and the agent policy. The key things come from the user, how you're supposed to handles handle the pieces of information. And if the user talks about was asking question from the knowledge basis, it has to answer the questions and so forth. It decides what to do and give it to the response generator which generates the natural language. So here is an example of a short example. It's kind of the same as what we're doing, just a little bit more terse here. Okay, so let's talk about the GENIE worksheet. Now I'm just going to give you the high level. I don't have the time to get into all the details. It took me, I think that I was working on this before Harshit showed up even it took us a while. Harshit is the person who is the first author on this paper. The key idea here is that we have to have a representation that is good for the programmer and good for the implementation. And I actually believe that the design is such that anything", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_4013029_ms_-_4087113_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 4013029, "end_ms": 4087113}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 4070215 ms - 4148641 ms", "content": "Title: CS224V Lecture 3 > Transcript > 4070215 ms - 4148641 ms\n\nContent: on this paper. The key idea here is that we have to have a representation that is good for the programmer and good for the implementation. And I actually believe that the design is such that anything I ask the developer to do when they describe a task is necessary. Okay, what is the information? And they are these, you know, this I'm showing you one sheet, but they are actually linked. One sheet may require another sheet. It's kind of like when you go on the website, you open a page and then you take you to another page and another page and so forth. So the information has to be linked. And the way to think about it is that you have to decide what is interesting about the conversation. You declare them as variables and then you say for each variable, what are you supposed to do with it? Okay, and when my whole worksheet is filled, so for example, when all these parameters are filled, then you execute an action associated with this worksheet. That's the developer. What the agent has to", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_4070215_ms_-_4148641_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 4070215, "end_ms": 4148641}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 4134705 ms - 4208087 ms", "content": "Title: CS224V Lecture 3 > Transcript > 4134705 ms - 4208087 ms\n\nContent: and when my whole worksheet is filled, so for example, when all these parameters are filled, then you execute an action associated with this worksheet. That's the developer. What the agent has to do is that as it listens to the user, it fills in the worksheets and that represents a dialogue state. And this dialogue state is used to as the history to interpret new sentences in the semantic parser. And this information is also used to decide what the agent needs to do next. Okay, so that's a high level. Let's go get a Little bit more detail. So here is the enrollment form. And I'm telling you all this because you're going to write an agent. So this is the kind of information that you need. I'm not going to teach you all the back end work, but this is the information that you need to write this agent. It's not that difficult, but here are the ideas. So look at the conversation on the right. It says I'm currently an all state customer. I'm considering changing the provider. I'm talking to", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_4134705_ms_-_4208087_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 4134705, "end_ms": 4208087}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 4196517 ms - 4262837 ms", "content": "Title: CS224V Lecture 3 > Transcript > 4196517 ms - 4262837 ms\n\nContent: agent. It's not that difficult, but here are the ideas. So look at the conversation on the right. It says I'm currently an all state customer. I'm considering changing the provider. I'm talking to an insurance agent. Now the fact that I'm an allstate customer, that's useful because I need to know who the competitor is. But if you just call me and say I want insurance, I'm not going to ask you who is your current provider. That's, you know, that's awkward. So. But if you offer it, I'm going to remember it. That's why the parameters can be required and not required. Anything that you think is useful, that the user may say, you capture it, but you may not want to ask them if they don't. So parameters can be required. I say, okay, I need some information. What's your marital status? So that's the first line by the way, Amir, who is your current provider? The second question is what is your marital status? Normally when you on a website you tick single or married. I want to not be general", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_4196517_ms_-_4262837_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 4196517, "end_ms": 4262837}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 4249329 ms - 4321009 ms", "content": "Title: CS224V Lecture 3 > Transcript > 4249329 ms - 4321009 ms\n\nContent: the first line by the way, Amir, who is your current provider? The second question is what is your marital status? Normally when you on a website you tick single or married. I want to not be general free text. I want to be an enumerated type. Right? But suppose the user says what do you mean by marital status? Then what the agent will do is that it looks. So when you describe an enum type, you specify the possible values. We will actually use this to explain to the user. Okay, all automatically the user doesn't. You don't have to code anything. The agent will says, oh, it means that are you married or single? So that's why we have an enum type. Then you say I'm married and say oh, got it. What is your spouse's name? The spouse name is not relevant unless you are married. So now the information has to be conditional. And so here we also allowed you, when you declare that I'm interested in the spouse name, it is predicated on the fact that the medal of status is equal to married. Okay.", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_4249329_ms_-_4321009_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 4249329, "end_ms": 4321009}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 4306847 ms - 4385597 ms", "content": "Title: CS224V Lecture 3 > Transcript > 4306847 ms - 4385597 ms\n\nContent: has to be conditional. And so here we also allowed you, when you declare that I'm interested in the spouse name, it is predicated on the fact that the medal of status is equal to married. Okay. So this is the kind of control you have over the information that you request. Then you can decide what the agent does. Okay, so for example, you say so when you declare a variable like course name, suppose the user says I want to take 224V. So at that point the action, whenever this course name is available, you can associate an action with it, because this is what the agent is going to do. For example, the agent says, I first of all have to check if the course is available and if it is available. If it is not available, I have to say to you that there are no seats available. I can help you find other courses. And I will remove the fact that you want 224V because it is not available. So this is the action the agent is going to do. So when you create an agent, you always have, you know, you get", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_4306847_ms_-_4385597_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 4306847, "end_ms": 4385597}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 4371629 ms - 4446075 ms", "content": "Title: CS224V Lecture 3 > Transcript > 4371629 ms - 4446075 ms\n\nContent: courses. And I will remove the fact that you want 224V because it is not available. So this is the action the agent is going to do. So when you create an agent, you always have, you know, you get to control what it does as the information comes in. Okay, so that's why they have. We have an action field associated with an agent. And finally, when the whole enrollment form, like the id, name, grade, type, num units, if they are filled, then you actually make a call to the API enroll with all these parameters. So you get to spell it out. What is when the worksheet is done? What, what action do you want to take? Okay, so that's an API call that you can or Python code that you can supply. So that's roughly the idea behind the worksheet. And here are some functions. You can ask the agent to say something. You can actually propose a worksheet to be filled, or you can exit the worksheet. So this is a little bit more advanced. Um, I don't know if you're gonna see that in the homework. No.", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_4371629_ms_-_4446075_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 4371629, "end_ms": 4446075}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 4433231 ms - 4507713 ms", "content": "Title: CS224V Lecture 3 > Transcript > 4433231 ms - 4507713 ms\n\nContent: say something. You can actually propose a worksheet to be filled, or you can exit the worksheet. So this is a little bit more advanced. Um, I don't know if you're gonna see that in the homework. No. Okay, we'll discuss this in more details. We'll probably stick with the relatively simple stuff. All right, so for a database, you have to define the schema, which are like all the things that are in the table. So just give you a little bit of background on the agent. So what happened now is that you've you describe the action worksheet and the database worksheet, G and E is using LLM for everything that has to do with natural language, but it actually has a control over it. As we said, this is the parser, the agent policy, and then the response generator. So the whole time it is interpreting the information, updating information, and it knows what the whole context is. And at any one point, it is providing the prompt that the LLM need to resolve that one particular piece of input or", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_4433231_ms_-_4507713_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 4433231, "end_ms": 4507713}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 4488571 ms - 4578979 ms", "content": "Title: CS224V Lecture 3 > Transcript > 4488571 ms - 4578979 ms\n\nContent: the information, updating information, and it knows what the whole context is. And at any one point, it is providing the prompt that the LLM need to resolve that one particular piece of input or output for that particular turn. So it is the outside, the executive control, that understands what is going on in the entire dialogue. Okay, so LLM is just used, like, just for the IO subroutine. So the semantic parser, it's roughly, you give me a name, I will parse it the fields in the data in the worksheet. And if it is a Natural language, then I translate it into a query. And if you happen to do something like, I want to take a course that satisfies the significance implementation requires. For four units, you are specifying an API parameter as well as a query. Okay, this is something that we don't know anybody else that can deal with. It's very natural, but most people just deal with either a query or a API call. But here it is compounding everything and we just. When you give me like", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_4488571_ms_-_4578979_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 4488571, "end_ms": 4578979}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 4560391 ms - 4633195 ms", "content": "Title: CS224V Lecture 3 > Transcript > 4560391 ms - 4633195 ms\n\nContent: we don't know anybody else that can deal with. It's very natural, but most people just deal with either a query or a API call. But here it is compounding everything and we just. When you give me like something like this, we fill in the information and we are able to capture this integration of knowledge requests as well as API calls. Okay? And roughly, this is what the runtime does. The semantic parser. When the user says something, it assigns the variables to the worksheet. It generates the database queries. The agent policy decides what to do. It checks out all the queries. If they are missing required parameter, it will say, oh, add ask parameter to the list. If the query is complete, you evaluate it, you update the variables. If you are talking about a task worksheet, it looks at the variable if it is assigned, and if you have, if it is. If you need to ask for confirmation before you execute an action, you go do that, or you just go execute the action. And the same thing with the", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_4560391_ms_-_4633195_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 4560391, "end_ms": 4633195}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 4617973 ms - 4694237 ms", "content": "Title: CS224V Lecture 3 > Transcript > 4617973 ms - 4694237 ms\n\nContent: variable if it is assigned, and if you have, if it is. If you need to ask for confirmation before you execute an action, you go do that, or you just go execute the action. And the same thing with the fields. If it is, oh, if the field is unfilled, you go, if it is required, you ask the user for information on the field. And if a form is complete, then you do the action. Okay, so this is just interpreting the form as it is filled out by the semantic parser, and then it generates the response. And this is what the agent does. And when you have a system like this, it automatically handles the kind of conversations I showed you. You can take many, many turns, do many, many different things. But we just run this algorithm for each turn. Okay? And so here is just some examples of how, how complicated the agents may be. But it is just, this algorithm takes care of it. Suppose I say, I would like to take this course for letter grade and three units. Oh, I have all the information. You go", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_4617973_ms_-_4694237_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 4617973, "end_ms": 4694237}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 4682573 ms - 4749065 ms", "content": "Title: CS224V Lecture 3 > Transcript > 4682573 ms - 4749065 ms\n\nContent: the agents may be. But it is just, this algorithm takes care of it. Suppose I say, I would like to take this course for letter grade and three units. Oh, I have all the information. You go ahead, oh, I'm enrolling you. Would you like to confirm? And then you change your mind. You say, wait, does C224V allow for four units? And then you say, yes, it allows for four units. Then you can just go ahead and change it to four units. The worksheet gets updated properly and we just all go execute it. Okay? You don't have to write any code to worry about the user making changes during the course of the conversation. It just falls out from the simple algorithm in the past. When we built dialogue trees, every little things like this has to be explicitly scripted and it just riddled like crazy. Yes. Erin, you have a question? So I noticed one thing. When the agent reported the average number of hours on the courses, that information is not on Carta. Carta just gives you a bar chart. So did it", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_4682573_ms_-_4749065_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 4682573, "end_ms": 4749065}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 4737713 ms - 4813935 ms", "content": "Title: CS224V Lecture 3 > Transcript > 4737713 ms - 4813935 ms\n\nContent: Erin, you have a question? So I noticed one thing. When the agent reported the average number of hours on the courses, that information is not on Carta. Carta just gives you a bar chart. So did it figure out how to take the average from that information? I don't know what the internal API does, do you? I mean what you see may be different from what you can get on the API call. Yeah, and you can compute them too. I mean you can. I don't know what it does, but if it is simple thing, it can do an average or whatever it is. The bar chart is probably a presentation on the data. Okay, so and I just want to focus on the fact that a conversation can be long. You can say I want to do three units. And then you get into a long, long discussion and at the very end, and I'm enrolling you, I have to remember the fact that you said you wanted three units. Okay, so this is the kind of thing that you get automatically by keeping track of the key variables in the worksheet. Okay, so this is the basic", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_4737713_ms_-_4813935_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 4737713, "end_ms": 4813935}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 4795407 ms - 4877849 ms", "content": "Title: CS224V Lecture 3 > Transcript > 4795407 ms - 4877849 ms\n\nContent: the fact that you said you wanted three units. Okay, so this is the kind of thing that you get automatically by keeping track of the key variables in the worksheet. Okay, so this is the basic idea. We'll get into the how we build things later and I just want to show you some of the quick results. And this is comparing it with function calling. There was a question about function calling earlier and as you can see here, we go into the details later. But the accuracy and the completion of the goal is all above the 80% which is much better than for example, what GPT can do. One of the biggest problem with GPT is it just kind of keeps loses track of all the information that it gives it. Okay, the fact that you mentioned three units was so long ago, it wouldn't realize that this is important and we wouldn't keep track of it. Okay, so this is the basic idea is that we're just using the external system to kind of manage or to keep track of what is important. And so from an agent developer's", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_4795407_ms_-_4877849_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 4795407, "end_ms": 4877849}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 4859971 ms - 4931483 ms", "content": "Title: CS224V Lecture 3 > Transcript > 4859971 ms - 4931483 ms\n\nContent: we wouldn't keep track of it. Okay, so this is the basic idea is that we're just using the external system to kind of manage or to keep track of what is important. And so from an agent developer's point of view, the key idea is that you have to decide what is it that you want to record when the user says anything, if they mention the insurance company that they are working with, write it down, whatever you want to remember. You make sure that you define it and it will be kept track of and it can give you the long context that you need. So this is, is roughly the basic idea that you have to keep in mind when you design your agents. So in summary here, it's like GENIE worksheet is a declarative programming language. It specifies the task at a very high level. It's like, you cannot skip any of this, and that is it. And then you provide the databases. It is a runtime system that deals with the different turns the users are making, and it does it by interpreting the worksheet. And then you", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_4859971_ms_-_4931483_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 4859971, "end_ms": 4931483}}
{"document_title": "CS224V Lecture 3", "section_title": "CS224V Lecture 3 > Transcript > 4916683 ms - 5138035 ms", "content": "this, and that is it. And then you provide the databases. It is a runtime system that deals with the different turns the users are making, and it does it by interpreting the worksheet. And then you parses it perfect performs the queries and actions, and then it poses questions back to the end users. If I, you know, we will talk about the history of all the research that went into using neural networks, neural models for conversational agents, and it is, you know, and they just cannot handle a conversation like what I showed you. Okay. So. All right. And well, thank you. And I will see you on Wednesday. It.", "block_metadata": {"id": "CS224V_Lecture_3_>_Transcript_>_4916683_ms_-_5138035_ms", "document_type": "transcript", "lecture_number": 3, "start_ms": 4916683, "end_ms": 5138035}}
