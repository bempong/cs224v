{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Chapter Summaries > TRAVEL: Task-oriented Agents", "content": "Title: CS224V Lecture 15 > Chapter Summaries > TRAVEL: Task-oriented Agents\n\nContent: Today I'm going to focus on task oriented agents. There are two types of such agents. First one is just based on slot based tasks. And then we'll go into knowledge and task based agents. How can you evaluate Gini agents or like any conversation agents?", "block_metadata": {"id": "CS224V_Lecture_15_>_Chapter_Summaries_>_TRAVEL:_Task-oriented_Agents", "document_type": "chapter summary", "lecture_number": 15, "start_ms": 51525, "end_ms": 357315}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Chapter Summaries > User Involvement Agents vs Mixed-Initiative Agents", "content": "Title: CS224V Lecture 15 > Chapter Summaries > User Involvement Agents vs Mixed-Initiative Agents\n\nContent: OpenAI's customer service bot itself uses a dialogue tree instead of letting the user give natural language response. The key difference here is the agent policy. The agent policy decides what the what the agent should say. Why are mixed initiative agents hard? And why?", "block_metadata": {"id": "CS224V_Lecture_15_>_Chapter_Summaries_>_User_Involvement_Agents_vs_Mixed-Initiative_Agents", "document_type": "chapter summary", "lecture_number": 15, "start_ms": 357775, "end_ms": 922065}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Chapter Summaries > Dialogue Tree", "content": "Title: CS224V Lecture 15 > Chapter Summaries > Dialogue Tree\n\nContent:  dialog trees provide you control which LLMs cannot. But the biggest disadvantage is its expressiveness. It is just limited to intent and slots. The number of states that you have to define just explodes. And it is practically impossible to respond to all the user queries.", "block_metadata": {"id": "CS224V_Lecture_15_>_Chapter_Summaries_>_Dialogue_Tree", "document_type": "chapter summary", "lecture_number": 15, "start_ms": 923085, "end_ms": 1090705}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Chapter Summaries > Tutorial: Multi-Level Agents", "content": "Title: CS224V Lecture 15 > Chapter Summaries > Tutorial: Multi-Level Agents\n\nContent: Multi Wars was one of the biggest data set for task oriented agents. It has 30 number of slots, so there are 30 fields that you will elicit from the user. Now let's talk about the second kind of such agents using dialog acts.", "block_metadata": {"id": "CS224V_Lecture_15_>_Chapter_Summaries_>_Tutorial:_Multi-Level_Agents", "document_type": "chapter summary", "lecture_number": 15, "start_ms": 1091725, "end_ms": 1516505}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Chapter Summaries > Dialogue state tracking and the semantic parsing", "content": "Title: CS224V Lecture 15 > Chapter Summaries > Dialogue state tracking and the semantic parsing\n\nContent: Each utterance that a user has, it should be contextualized. Let's look at why state machine based agents do not well. How they compare to the real life real life scenarios.", "block_metadata": {"id": "CS224V_Lecture_15_>_Chapter_Summaries_>_Dialogue_state_tracking_and_the_semantic_parsing", "document_type": "chapter summary", "lecture_number": 15, "start_ms": 1517925, "end_ms": 2005485}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Chapter Summaries > Gini Worksheets and the GENIE Agent", "content": "Title: CS224V Lecture 15 > Chapter Summaries > Gini Worksheets and the GENIE Agent\n\nContent: The design of Gini worksheets was based on some key concepts or things that you want to support. It should be fully mixed initiative agent. Developer only needs to define all the happy parts. A runtime system can handle all the unhappy parts.", "block_metadata": {"id": "CS224V_Lecture_15_>_Chapter_Summaries_>_Gini_Worksheets_and_the_GENIE_Agent", "document_type": "chapter summary", "lecture_number": 15, "start_ms": 2006665, "end_ms": 2117549}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Chapter Summaries > Genie Worksheets: The Agent Framework", "content": "Title: CS224V Lecture 15 > Chapter Summaries > Genie Worksheets: The Agent Framework\n\nContent: The first key thing that these agents should have is the developer control. Second thing is they should be responsive to the users. Third thing is it should be able to support all the knowledge queries. Gini worksheets can handle mixed initiatives.", "block_metadata": {"id": "CS224V_Lecture_15_>_Chapter_Summaries_>_Genie_Worksheets:_The_Agent_Framework", "document_type": "chapter summary", "lecture_number": 15, "start_ms": 2117637, "end_ms": 2675215}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Chapter Summaries > Gini Worksheets", "content": "Title: CS224V Lecture 15 > Chapter Summaries > Gini Worksheets\n\nContent: Gini worksheets track user utterances, tasks and knowledge queries. We have five agents acts in this in GENIE worksheet which are report, confirm, say propose and ask. And it uses LLM for doing semantic parsing and generating response.", "block_metadata": {"id": "CS224V_Lecture_15_>_Chapter_Summaries_>_Gini_Worksheets", "document_type": "chapter summary", "lecture_number": 15, "start_ms": 2676635, "end_ms": 3352135}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Chapter Summaries > Genie 2.8: Agent Policy and how it works", "content": "Title: CS224V Lecture 15 > Chapter Summaries > Genie 2.8: Agent Policy and how it works\n\nContent: We use the GENIE runtime system to compute the agent response. It first runs the knowledge queries, it performs all the actions that have been defined by the developer, and it generates the agent acts. Using the symbolic module, we can improve the LLM based system's ability to follow these instructions.", "block_metadata": {"id": "CS224V_Lecture_15_>_Chapter_Summaries_>_Genie_2.8:_Agent_Policy_and_how_it_works", "document_type": "chapter summary", "lecture_number": 15, "start_ms": 3353475, "end_ms": 3900235}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Chapter Summaries > How can we evaluate Gini Agents?", "content": "Title: CS224V Lecture 15 > Chapter Summaries > How can we evaluate Gini Agents?\n\nContent: How we evaluate Gini worksheets is using real users. We evaluated on three domains and the three domains that we evaluated were Bank, Trivia and Trip. Most of the errors were due to the agent not following the agent policy that was described. And again there are annotation problems.", "block_metadata": {"id": "CS224V_Lecture_15_>_Chapter_Summaries_>_How_can_we_evaluate_Gini_Agents?", "document_type": "chapter summary", "lecture_number": 15, "start_ms": 3902495, "end_ms": 4492195}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Chapter Summaries > Five tips for building responsive agents in LLM", "content": "Title: CS224V Lecture 15 > Chapter Summaries > Five tips for building responsive agents in LLM\n\nContent:  LLMs need succinct to represent context and fewer instructions to make them perform better in lesser known domains. The existing academic data set, at least for task oriented agents, are not enough for evaluation. You need to evaluate them with real users.", "block_metadata": {"id": "CS224V_Lecture_15_>_Chapter_Summaries_>_Five_tips_for_building_responsive_agents_in_LLM", "document_type": "chapter summary", "lecture_number": 15, "start_ms": 4494255, "end_ms": 4782605}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 51525 ms - 196183 ms", "content": "Title: CS224V Lecture 15 > Transcript > 51525 ms - 196183 ms\n\nContent: It okay. Hey everyone. So Monica is traveling and she's in Miami. And so today I'll give the lecture. It's about task oriented agents. We have already seen some of it in the lecture 3. I'll probably, I'll like just continue over it. But before that I want to like go over what are the different kind of agents we have already seen. There are research agents such as like Storm and Coast Storm which use multi agent conversations to write long form documents. Then we looked at WikiChart which creates hallucination free agents and you can do retrieval and be quite confident that the responses that it gives are like they don't have any hallucinations. Then we looked at how can we do data analytics using things like SQL. We can do semantic parsing using just purely by using alm. And we also looked at how can we do graph traversal and generate Sparkle query to go over wikidata. And then in the last class we looked at qualitative coding and how we can analyze free text data using if you are", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_51525_ms_-_196183_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 51525, "end_ms": 196183}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 182911 ms - 250825 ms", "content": "Title: CS224V Lecture 15 > Transcript > 182911 ms - 250825 ms\n\nContent: at how can we do graph traversal and generate Sparkle query to go over wikidata. And then in the last class we looked at qualitative coding and how we can analyze free text data using if you are given a schema you can extract the data and then fill it out in a table and then use that for your analysis. All of us I think probably have experience with services like Alexa and Siri. We also briefly mentioned that they are just slot filling APIs and how they work. Today I'm going to focus on task oriented agents and mostly we'll be focusing on what do we mean by task oriented agents and especially in like mixed initiative agents. So there are like two types of such agents that we'll go into. First one is just based on slot based tasks. So there are examples of multi wars which has a neural policy. And then we'll go into knowledge and task based agents. This has like all of you like tried the course assistant in your second assignment and we'll go into like how do we do that using GENIE", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_182911_ms_-_250825_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 182911, "end_ms": 250825}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 237873 ms - 303021 ms", "content": "Title: CS224V Lecture 15 > Transcript > 237873 ms - 303021 ms\n\nContent: policy. And then we'll go into knowledge and task based agents. This has like all of you like tried the course assistant in your second assignment and we'll go into like how do we do that using GENIE worksheets and we'll go into the details. We have also looked at social bots. I think Monica briefly mentioned them in lecture five and seven. There was a persuasion boss bot and a chit chat bot, the Stanford Chirpy box. So let's look at what is the state of the commercial virtual assistants which purely use function calling. So let's say I'm a user and I ask like how's the weather in Stanford? What will you get out of it? So it might just like tell you, oh, it will make an API call to the weather API. It will add the parameter that what is the weather location is equal to Stanford and it will give you the Result. Okay, this looks good. But if I have another task which is can you book me a flight in Miami? What will be the response? Ideally, what should be the response is very different", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_237873_ms_-_303021_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 237873, "end_ms": 303021}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 290265 ms - 352875 ms", "content": "Title: CS224V Lecture 15 > Transcript > 290265 ms - 352875 ms\n\nContent: give you the Result. Okay, this looks good. But if I have another task which is can you book me a flight in Miami? What will be the response? Ideally, what should be the response is very different from what we get because it is just a function calling based virtual assistant. It just uses the Google Search API, fills in the parameter, what is the search content and it just gives us a bunch of results instead of helping us with how can you actually book the flight to Miami. So it cannot even do like some of these trivial tasks such as booking a flight. And we look into like why is that the case and how can we improve that? So in today's lecture I'll go over the key concepts for task oriented agents. Then we'll look into the prior work that has been done on agent policy. Then we'll go into details for in like GENIE worksheets, what is the design rationale, what are the technical details? And then finally we'll talk about how you can evaluate Gini agents or like any conversation agents,", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_290265_ms_-_352875_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 290265, "end_ms": 352875}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 341665 ms - 405987 ms", "content": "Title: CS224V Lecture 15 > Transcript > 341665 ms - 405987 ms\n\nContent: details for in like GENIE worksheets, what is the design rationale, what are the technical details? And then finally we'll talk about how you can evaluate Gini agents or like any conversation agents, what is the right way of evaluating them? Basically we'll talk about that. So let me go into the architecture first. So here we have just user initiative based agents. There can be like two types of such agents. One is like the knowledge agents that we have looked at like SQL, wikichat and et cetera. Then they're like virtual assistants. What they do is you have a user utterance, you have the dialogue history, you can do semantic parsing. When you do semantic parsing, you get the queries and then you can execute these queries and get the response. So for example, I am saying find me spicy Chinese restaurant, Palo Alto. It will generate this SQL query, it will execute it against the database and then it will generate the response. So these are simple user initiative based agents. When we", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_341665_ms_-_405987_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 341665, "end_ms": 405987}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 392233 ms - 461701 ms", "content": "Title: CS224V Lecture 15 > Transcript > 392233 ms - 461701 ms\n\nContent: restaurant, Palo Alto. It will generate this SQL query, it will execute it against the database and then it will generate the response. So these are simple user initiative based agents. When we talk about task oriented agents, they have to be multi initiatives. The key difference here is the agent policy. And based on how you define this agent policy, there are different kinds of agents that you can create. The agent policy decides what the what the agent should say, it can respond to the user, it can ask follow up questions, it can execute some other arbitrary query. But so the main question is like why are mixed initiative agents hard? And why? The virtual assistants that we have just seen, why can they not be like mixed initiative and why are they not very useful? So let's look at the agent initiative only agents. So here only the agent will guide the conversation. The user cannot guide these conversations and they usually follow the happy path, which is that the agent will ask,", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_392233_ms_-_461701_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 392233, "end_ms": 461701}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 449013 ms - 514935 ms", "content": "Title: CS224V Lecture 15 > Transcript > 449013 ms - 514935 ms\n\nContent: agent initiative only agents. So here only the agent will guide the conversation. The user cannot guide these conversations and they usually follow the happy path, which is that the agent will ask, oh, it has an API, it will ask you for values of all the parameters and it expects you to just respond with the answers for these parameters. So for example, like a very simple example is if I call United today and the agent will say, oh, welcome back Harshit, how can I help you? You can say flight status, mileage plus account services, but if you have any other queries, you have to talk to the representative. So these agents, they like these conversational agents, they cannot handle arbitrary queries and that's why they fall back to the representative. However, mixed initiative agents are very different and they follow an unhappy path at any point of time. The user can initiate any new query, they can ask for questions, they can change their mind, or they can even just like end the, end", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_449013_ms_-_514935_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 449013, "end_ms": 514935}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 500439 ms - 558261 ms", "content": "Title: CS224V Lecture 15 > Transcript > 500439 ms - 558261 ms\n\nContent: different and they follow an unhappy path at any point of time. The user can initiate any new query, they can ask for questions, they can change their mind, or they can even just like end the, end the task. So let's look at some of these examples. Let's say there's a banker and then there's a client. If the banker asks how much money do you wish to transfer? The client instead of saying the amount that they want to transfer, they can just say that oh, how much money do I have in my account? For the same question, the client also say oh, never mind, I don't want to do this. There are other examples as well, such as like would you like to open a fixed rate saving account? The client can ask oh, what is it? So there are like all these different kind of questions that the client can ask. And there it should also be able to handle out of domain queries such as if the client says, oh, I had a horrible experience, I demand a free trip to Thailand. The banker can say that oh, I can't believe", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_500439_ms_-_558261_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 500439, "end_ms": 558261}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 546501 ms - 612711 ms", "content": "Title: CS224V Lecture 15 > Transcript > 546501 ms - 612711 ms\n\nContent: there it should also be able to handle out of domain queries such as if the client says, oh, I had a horrible experience, I demand a free trip to Thailand. The banker can say that oh, I can't believe what happened and it will just give it like two free trips. So let's classify some of these unhappy parts. So as we just saw in the examples, the user can ignore or refuse to answer, it can ask for more information, it can change it. The user can change their mind and just change the answer to a previous question and they can ask the agent to repeat themselves and give more information about it. The most important one is I think like make. A user can make statements or unexpected requests which are out of domain. Now if you look at like all these unhappy parts, we can say that oh, LLMs are actually really good at handling all of these unhappy parts and they should like we should just use LLMs. But OpenAI's customer service bot itself uses a dialogue tree instead of letting the user give", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_546501_ms_-_612711_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 546501, "end_ms": 612711}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 598687 ms - 677461 ms", "content": "Title: CS224V Lecture 15 > Transcript > 598687 ms - 677461 ms\n\nContent: really good at handling all of these unhappy parts and they should like we should just use LLMs. But OpenAI's customer service bot itself uses a dialogue tree instead of letting the user give natural language response and then having a conversation from there on. So the question is the commercial chatbots, they like to be conservative. Despite the LLM success, the question is why does anyone want to take a Guess why do you think, like we don't like all these companies are not using LLMs right now? I think there's a big risk, for example, in the financial sector if you take the wrong decision, I mean, you could have financial implications. Yeah, that's true. That's true. Anything else? Anyone? Okay, so what David said is correct. I'll expand on it. And here's an example of it. So Air Canada, they had an LLM, let the LLM operate the chatbot, and then Jake Moffett, who asked for a discount, the chatbot gave a discount to this passenger. And this was just out of nowhere, like there was no", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_598687_ms_-_677461_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 598687, "end_ms": 677461}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 662225 ms - 732693 ms", "content": "Title: CS224V Lecture 15 > Transcript > 662225 ms - 732693 ms\n\nContent: they had an LLM, let the LLM operate the chatbot, and then Jake Moffett, who asked for a discount, the chatbot gave a discount to this passenger. And this was just out of nowhere, like there was no policy that they can give a discount. But since the LM was, since the chatbot was LLM operated, it just gave a discount. And then the tribunal ruled that Air Canada has to pay mofed some $800 in damages and tribunal fees. So there are two key things that we have to keep in mind when we want to design these agent policies. One is control, which is very hard with LLMs. You cannot give wrong information. You cannot give like all these random discounts. And then the second thing is helpfulness. So with dialogue trees kind of agents, you get the control, but you are not very helpful to the user. So as we saw, when the user has any questions, you cannot answer them. So we want some kind of agent policy that can help us with the control as well as be helpful. So let's look at like what are the,", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_662225_ms_-_732693_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 662225, "end_ms": 732693}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 717375 ms - 788155 ms", "content": "Title: CS224V Lecture 15 > Transcript > 717375 ms - 788155 ms\n\nContent: as we saw, when the user has any questions, you cannot answer them. So we want some kind of agent policy that can help us with the control as well as be helpful. So let's look at like what are the, what people have done and when they're creating these agent policies. So there are two types of agent policies that you can choose from. One is a neural policy and the other one is a programmed agent policy. We know that when you have a neural policy, it has its own drawbacks. So first of all, once you have trained, let's say you have a huge corpus of dataset, you train on all those conversations and you learn a policy. The problem is if you want to change anything in the policy or like the developer wants the agent to say something else in some different situation, it won't be able to learn that. However, when you use a program agent policy, you can at least try to change it. So there are three kinds of agent policy specifications. So these are basically programmed agent policy. The first", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_717375_ms_-_788155_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 717375, "end_ms": 788155}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 774735 ms - 842025 ms", "content": "Title: CS224V Lecture 15 > Transcript > 774735 ms - 842025 ms\n\nContent: However, when you use a program agent policy, you can at least try to change it. So there are three kinds of agent policy specifications. So these are basically programmed agent policy. The first one is using dialogue trees. These are defined as finite state machine where you have to define all the transitions. And if you don't define all these transition, your dialogue tree based agent will just fail at various instances. The second one is based on dialog acts. These are parameterized finite state machines where you define that okay. Each utterance will have a dialogue act associated with them. And now you have a state machine with these dialog acts. Your user dialogue act will go to an agent dialog act and based on that you can make this transaction. But again, still it kind of resolves some of the issues with the dialogue tree base dialogue tree based state machine agents, but still there are like issues with it and we'll look at it later. And the third one is using GENIE", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_774735_ms_-_842025_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 774735, "end_ms": 842025}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 828991 ms - 894703 ms", "content": "Title: CS224V Lecture 15 > Transcript > 828991 ms - 894703 ms\n\nContent: resolves some of the issues with the dialogue tree base dialogue tree based state machine agents, but still there are like issues with it and we'll look at it later. And the third one is using GENIE worksheet. So GENIE worksheet is just declarative. You don't have to define all these states, you can just specify this is the API and these are the data corpus and you can define your agent policy. And it kind of like handles all the unhappy path using the GENIE runtime. And what we are doing here is we are basically increasing the level of abstraction as we go from the dialogue tree based policies to GENIE worksheets. Now let's look at like into details what these dialogue tree based agents look like and how the agent policy is defined. So for these, the initiatives, as we have already discussed, the initiatives are just taken by the user and the agent just asks for the slots. And how does it do that? Is it uses natural language understanding, but initially it just performs intent", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_828991_ms_-_894703_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 828991, "end_ms": 894703}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 880089 ms - 948981 ms", "content": "Title: CS224V Lecture 15 > Transcript > 880089 ms - 948981 ms\n\nContent: discussed, the initiatives are just taken by the user and the agent just asks for the slots. And how does it do that? Is it uses natural language understanding, but initially it just performs intent classification. And you can have a fixed set of intents. It will just classify what is the user trying to say. And based on that it fills in the slot and value pair. So here's an example where the user utterances that I like to transfer $1,000 or $100, it doesn't intend classification that the user wants to transfer money. And based on that it then selects which slot value pair can I fill in? So here are some other examples of these dialog and here's an example of what a dialogue tree can look like. So if the agent says, hello, how can I help you? And the user says, I'm looking for a restaurant for Valentine's Day, it will select that oh, based on the user query I want to elicit some slots. And now when it goes into this transition, when it makes this transition, it has some hard coded", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_880089_ms_-_948981_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 880089, "end_ms": 948981}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 934373 ms - 1001425 ms", "content": "Title: CS224V Lecture 15 > Transcript > 934373 ms - 1001425 ms\n\nContent: for Valentine's Day, it will select that oh, based on the user query I want to elicit some slots. And now when it goes into this transition, when it makes this transition, it has some hard coded utterances that it can say. So for example, in this case it will say oh, what kind of restaurant do you want to go to? Do you want to go to? And then the user might choose like these different kind of utterances such as tarun on Callaway or something that has pizza. And based on that there are like different parts that this the dialogue tree based agent can take. However, what if the user says, I don't know, what do you recommend? Now as you can see the agent cannot go from this path back to the recommend. So this is one of the biggest drawback of dialogue based agents. You can define all these different states, but then again you'll have to define. It just explodes. The number of states that you have to define just explodes. And it is practically impossible to respond to all the user queries.", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_934373_ms_-_1001425_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 934373, "end_ms": 1001425}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 988889 ms - 1057949 ms", "content": "Title: CS224V Lecture 15 > Transcript > 988889 ms - 1057949 ms\n\nContent: states, but then again you'll have to define. It just explodes. The number of states that you have to define just explodes. And it is practically impossible to respond to all the user queries. So let's look at the pros and cons of dialog trees. Pros, as we have already discussed, they provide you control which LLMs cannot. But the biggest disadvantage is its expressiveness. It is just limited to intent and slots. So for example, a query like what are the top three restaurants that are near the airport or the fisherman's wharf? It cannot answer such queries because it requires you to be more expressive. You cannot just have slots to do this. And then the next problem is that it takes a lot of time to define all these different kind of states that you have to define. You have to take care of, oh, if you go from node A to node B, then is there a way of going back to node A? So this is even more difficult when you have like, you have to navigate different kind of products. And all these", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_988889_ms_-_1057949_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 988889, "end_ms": 1057949}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 1044301 ms - 1122811 ms", "content": "Title: CS224V Lecture 15 > Transcript > 1044301 ms - 1122811 ms\n\nContent: of, oh, if you go from node A to node B, then is there a way of going back to node A? So this is even more difficult when you have like, you have to navigate different kind of products. And all these are like handcraft for each of these problems. And finally, as we mentioned that you have to define all these different parts. The problem is the developer cannot anticipate that what are all the possible utterances and they cannot handle all these unexpected answers. And hence we have already seen and maybe even you have experienced that all these chatbots which are dialogue pre based and which you usually see on websites or any other platform, they usually break after one or two utterances. Now let's talk about the second kind of such agents. So these are finite state machine agents using dialog acts. So here is the paper, Multi Wars. It was one of the biggest data set for task oriented agents that came out in I think 2018 or 2017. So it has 1400 citation, 1400 plus citations. And it", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_1044301_ms_-_1122811_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 1044301, "end_ms": 1122811}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 1099307 ms - 1180399 ms", "content": "Title: CS224V Lecture 15 > Transcript > 1099307 ms - 1180399 ms\n\nContent: dialog acts. So here is the paper, Multi Wars. It was one of the biggest data set for task oriented agents that came out in I think 2018 or 2017. So it has 1400 citation, 1400 plus citations. And it was annotated in. So it has slot and value pairs, but it was annotated for different domains and it was done in Cambridge. So it has seven domains such as restaurant, hotel, attraction, train and taxi. And then it was converted into five domains. Police and hospital were dropped because of the annotation quality. And I'll talk about how this was annotated in a bit. But the main thing to notice is it has 30 number of slots, so there are 30 fields that you will elicit from the user. And it has a close ontology. So it defines that what are the values that you can use and as I mentioned, the representation is just slot and value pair based. So the whole concept of wizard of Oz is that you have two humans. One acts like a user and the other one acts as an agent. Both of them are crowd workers.", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_1099307_ms_-_1180399_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 1099307, "end_ms": 1180399}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 1166441 ms - 1235441 ms", "content": "Title: CS224V Lecture 15 > Transcript > 1166441 ms - 1235441 ms\n\nContent: is just slot and value pair based. So the whole concept of wizard of Oz is that you have two humans. One acts like a user and the other one acts as an agent. Both of them are crowd workers. They are paid to do this and they are. And the human agent is supposed to work as the automated agent. And both the workers are given a script that, okay, the human user will be given a script saying that, given an instruction that, oh, you have to say this, this, this, you can potentially change your mind in between. And all these are like basically scripted. And then the human worker has to behave like an automated agent and click buttons. This is the response that I'll give now. So there are like again like issues with such kind of such data set. For example, it does not reflect the real life scenarios where the workers might just change their mind multiple times, they might explore different kind of options. And as well as like, since the human agent has to press these buttons, there are errors", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_1166441_ms_-_1235441_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 1166441, "end_ms": 1235441}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 1223369 ms - 1292105 ms", "content": "Title: CS224V Lecture 15 > Transcript > 1223369 ms - 1292105 ms\n\nContent: where the workers might just change their mind multiple times, they might explore different kind of options. And as well as like, since the human agent has to press these buttons, there are errors that the human makes when they're selecting what to respond. And we can see like how big of a problem this is by seeing that this dataset has been annotated three times by different companies. But still there are like several errors in this dataset. But anyways, it is a great dataset. It got a lot of people started with task oriented agents. And let's look into like how do they define this whole task? So there is some meaning. So there's the speech act theory, which says that every utterance of a human being can be classified into different sort of actions. And these finite number of actions, you can define them as requests, warnings, invitations, promises, etc. So the whole idea is that given a user utterance, you can have some sort of classification for that user utterance. So in nlp, like", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_1223369_ms_-_1292105_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 1223369, "end_ms": 1292105}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 1278339 ms - 1347341 ms", "content": "Title: CS224V Lecture 15 > Transcript > 1278339 ms - 1347341 ms\n\nContent: can define them as requests, warnings, invitations, promises, etc. So the whole idea is that given a user utterance, you can have some sort of classification for that user utterance. So in nlp, like we go away from this speech act theory and we call individual user utterances the dialogue acts and all these. So in wizard of Oz all these user utterances were classified as one of the dialogue acts. And how this dialogue act based state machine works is like, given a user dialogue act it defines transitions to the agent dialogue act. And similarly when given an agent dialogue act, it has transitions to the user dialogue act. Now let's look at how we define this dialogue state. An example of this dialogue state machine. So for just knowledge based navigation or like the knowledge agents, it is very simple. You have a query, it goes to query response, there's like backend back and forth between the user to the agent and the final one is done. So once you are done, the state machine", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_1278339_ms_-_1347341_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 1278339, "end_ms": 1347341}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 1333835 ms - 1401595 ms", "content": "Title: CS224V Lecture 15 > Transcript > 1333835 ms - 1401595 ms\n\nContent: it is very simple. You have a query, it goes to query response, there's like backend back and forth between the user to the agent and the final one is done. So once you are done, the state machine Terminates. However, in the case of action based agents, you can define these different kinds of dialog acts. So for example, the user dialogue act could be request action, the agent could be slot, fill, question and once you transition through all these states, you can go to the done state and then it will be your task will be completed. However, although these dialogue name acts are independent, the actual content could be domain specific. So here's just an example of what Multi wars looks like. So here you'll see that there are like act types. Some of them are common to all the domains and some of them are specific to some of the domains. So the one with asterisk they are common to all the domains such as inform, request, greet, buy and request more and the other acts like select,", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_1333835_ms_-_1401595_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 1333835, "end_ms": 1401595}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 1388817 ms - 1450791 ms", "content": "Title: CS224V Lecture 15 > Transcript > 1388817 ms - 1450791 ms\n\nContent: and some of them are specific to some of the domains. So the one with asterisk they are common to all the domains such as inform, request, greet, buy and request more and the other acts like select, recommend, not found are specific to some of these domains. So these are the act types, the dialogue acts that we just discussed. Then there are slots, the values that you have to fill. Again, some of these are common to all the domains such as address, postcode, phone, and then some of these are just specific to some of the novens such as name, number of choices, area. Now let's look at one of the example from the Multi wars dataset. So here we have the user saying, I'm looking for a restaurant. The restaurant should serve world food and should be at the center. The agent says, unfortunately, I cannot find a restaurant that serves that kind of food in that area. The user then replies, oh, what expensive restaurants are there? The agent says, the Cambridge Chop House is expensive and it's", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_1388817_ms_-_1450791_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 1388817, "end_ms": 1450791}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 1440047 ms - 1502325 ms", "content": "Title: CS224V Lecture 15 > Transcript > 1440047 ms - 1502325 ms\n\nContent: I cannot find a restaurant that serves that kind of food in that area. The user then replies, oh, what expensive restaurants are there? The agent says, the Cambridge Chop House is expensive and it's British food, is that okay? The user says, no, try for a restaurant that serves Korean food. Agent goes and finds a Korean food Seoul restaurant and asks like would you like me to make a reservation? And then the user says okay, yes, make it for two, I would be happy to reserve it. The user goes, thank you. And then the reservation is made. Now we can define this whole conversation into different parts. So the initial three turns from user and the agent, they are based on search and it uses the dialogue act such as result and actions and actions are suggested based on the results. Then comes the action slot filling part where once the user has searched for all the options that they have, then they can fill in all these slot. Then the agent can fill in all these slot values by asking the", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_1440047_ms_-_1502325_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 1440047, "end_ms": 1502325}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 1490651 ms - 1566143 ms", "content": "Title: CS224V Lecture 15 > Transcript > 1490651 ms - 1566143 ms\n\nContent: the action slot filling part where once the user has searched for all the options that they have, then they can fill in all these slot. Then the agent can fill in all these slot values by asking the user the kind of reservation that they want to make and the other parameters that can help in calling the API. And then finally once the agent has all the information from the user, it can call the API and execute the action. Now let's look at the dialogue state tracking. So what we mean is like each utterance that a user has, it should be contextualized and the question is, how do we do that? So for example, here the agent starts with by saying, oh, hello, I'm Jeannie. And the user says I like a French restaurant. And when the user says that I like a French restaurant, it has a context which is just the first line. However, if we go to the second turn, which is how far is it from here? What should be the context of this utterance? No, so the user is saying that how far is it from here?", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_1490651_ms_-_1566143_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 1490651, "end_ms": 1566143}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 1545159 ms - 1630467 ms", "content": "Title: CS224V Lecture 15 > Transcript > 1545159 ms - 1630467 ms\n\nContent: is just the first line. However, if we go to the second turn, which is how far is it from here? What should be the context of this utterance? No, so the user is saying that how far is it from here? What should we give the context to the agent for this user utterance? Would it be the current location? Yeah. So it is the whole conversation of the user. Because if you don't give any information about like oh, is the user asking about the French restaurant? How will it know that oh, how far is it from here? So for example, if we go to turn 9, then the context will be the complete 9 turns before this conversation. Let's look at like how people have given this dialogue context and done dialogue straight tracking. So here's a work from Mehrad. He was in our lab and he worked on a dataset called RISA Wars. They improved the dataset and they have this on the right hand side as you can see. Like this is the architecture that they use for dialogue state tracking. And this is before people", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_1545159_ms_-_1630467_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 1545159, "end_ms": 1630467}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 1618643 ms - 1688447 ms", "content": "Title: CS224V Lecture 15 > Transcript > 1618643 ms - 1688447 ms\n\nContent: RISA Wars. They improved the dataset and they have this on the right hand side as you can see. Like this is the architecture that they use for dialogue state tracking. And this is before people started using LLMs rigorously. So this contains four tasks. There is dialogue state tracking, there is next action prediction, there's response generation and agent dialogue act generation. And they fine tune a multitask neural network called mbart. But the important thing that we want to look in here is what is the formal state? So this is the context that you want to provide to the agent when doing, when generating response for the next agent response. So the formal state contains the user utterance, it contains the belief state. So believe state is basically what does the agent feel are the values of these different kind of slots. Then there are the results. So if the agent or the user requested for any information at any point of time, you have all the results in the. You have just gathered", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_1618643_ms_-_1688447_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 1618643, "end_ms": 1688447}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 1675677 ms - 1749305 ms", "content": "Title: CS224V Lecture 15 > Transcript > 1675677 ms - 1749305 ms\n\nContent: of these different kind of slots. Then there are the results. So if the agent or the user requested for any information at any point of time, you have all the results in the. You have just gathered all the results from the previous utterances. Then there is the agent dialogue act which tells us that what did the agent previously said? And then finally then there's the agent utterance which corresponds to the previous agent dialogue acts. And why do we want to provide this is instead of providing the whole conversation, we look, look at this later that why don't we provide the full conversation? When you provide the formal state it is succinct. Enough for the language models to perform semantic parsing or generate the response. So in this system or this agent they use a semantic parser and this is the context that they provide for any user utterance. There is also another thing which is Levenshtein belief state. So what this basically does is for any given utterance it computes the new", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_1675677_ms_-_1749305_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 1675677, "end_ms": 1749305}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 1734671 ms - 1806551 ms", "content": "Title: CS224V Lecture 15 > Transcript > 1734671 ms - 1806551 ms\n\nContent: this is the context that they provide for any user utterance. There is also another thing which is Levenshtein belief state. So what this basically does is for any given utterance it computes the new belief state and it calculates the diff between the original belief state and this is the new action or the newer context that we want to provide to the, let's say the agent policy to describe or to come up with the next agent act. So we have already seen like, okay, we have this dialogue state tracking and what we can do with it. And there's multi wars which has slots and value pair. But all the sentences that a user says cannot be described by slots. And this is one of the biggest drawbacks of function calling or function calling and API calling based systems. So for example, the first statement which says, I was hoping you could recommend something. This cannot be, you cannot have this as a slot value pair for an API. Are there any churches or museums on the east side? This cannot be", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_1734671_ms_-_1806551_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 1734671, "end_ms": 1806551}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 1793695 ms - 1865975 ms", "content": "Title: CS224V Lecture 15 > Transcript > 1793695 ms - 1865975 ms\n\nContent: which says, I was hoping you could recommend something. This cannot be, you cannot have this as a slot value pair for an API. Are there any churches or museums on the east side? This cannot be represented in an API call. Or the final one which says that I would like the latest train leaving that arrives by 9:15. You again cannot define all these in just an function calling agent. So let's look at like why state machine based agents do not work well and how is it, how they compare to the real life agents or like the real life scenarios. So if the user says, please book a table for five at 2:30 on Wednesday at Royal Spice, I also need to find a place to stay. So this user utterance, it has two dialogue acts associated with it which are in different domains. And if you look at multi wars or like all these state machine based methods, they cannot assign to user dialog acts. And even if they do, the number of states that you have to define just explodes. Here's another similar example", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_1793695_ms_-_1865975_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 1793695, "end_ms": 1865975}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 1852247 ms - 1921197 ms", "content": "Title: CS224V Lecture 15 > Transcript > 1852247 ms - 1921197 ms\n\nContent: or like all these state machine based methods, they cannot assign to user dialog acts. And even if they do, the number of states that you have to define just explodes. Here's another similar example where the agent has two dialog acts. So it reports the result that oh, I have booked the table for you. And then it asks like, oh, what kind of hotels are you also looking for? So as I said, these utterances have two dialogue acts each and this cannot be modeled in a state machine. There are like different kind of things that can happen. There can be multiple domains, there can be domain switches, and the user might also just want to abandon a transaction. And these kind of things cannot be modeled using state machine. And as I just mentioned that the state machine's size will just blow up if you want to cover all these cases and even if we could write all these transitions as if you just recall like what I showed in some of the one. One of the previous slides that the developer might not", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_1852247_ms_-_1921197_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 1852247, "end_ms": 1921197}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 1907149 ms - 1978825 ms", "content": "Title: CS224V Lecture 15 > Transcript > 1907149 ms - 1978825 ms\n\nContent: you want to cover all these cases and even if we could write all these transitions as if you just recall like what I showed in some of the one. One of the previous slides that the developer might not be able to come up with all these transitions and it will break whenever user might say something that is not covered. So in summary we talked about what formal dialogue state is. It just summarizes the whole conversation. And you can do this in a formal way. People can try to do this in natural language, but usually providing the succinct summary helps. Then there is an abstraction from the domain independent finite state machine. If you use user and dialog acts you can hide some of the. You don't have to have specific specific utterances for agents or the users. You can do some sort of abstraction on this finite state machine. And the agent policy is not specified, it is implied by the agent response. It is limited by the slot filling values. And occasionally, sometimes some of these", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_1907149_ms_-_1978825_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 1907149, "end_ms": 1978825}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 1964711 ms - 2037051 ms", "content": "Title: CS224V Lecture 15 > Transcript > 1964711 ms - 2037051 ms\n\nContent: on this finite state machine. And the agent policy is not specified, it is implied by the agent response. It is limited by the slot filling values. And occasionally, sometimes some of these agents can recommend if you have defined an API which can. Which just recommends. But again like going to that as we just mentioned, like going back to that state would be a difficult will be a challenge. So now we have seen that what these different the previous research has been what the commercial state of the art is. Now let's look at the design and rationale for how can we make better agents. So you have already used Gini worksheets. You use it for your assignment two, you created a worksheet and now we look into like how is it implemented and how we evaluate the GENIE worksheets. So the design of Gini worksheets was based on some key concepts or things that you want to support. The first one is that it should be fully mixed initiative agent. It provides a high level declarative specification.", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_1964711_ms_-_2037051_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 1964711, "end_ms": 2037051}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 2021481 ms - 2088736 ms", "content": "Title: CS224V Lecture 15 > Transcript > 2021481 ms - 2088736 ms\n\nContent: Gini worksheets was based on some key concepts or things that you want to support. The first one is that it should be fully mixed initiative agent. It provides a high level declarative specification. So it's declarative in the sense that you just have to define what task it should do. You don't have to define how it should be done. And you can specify the worksheet or the task that you have to do plus the knowledge corpus. And this we in this way we try to minimize the coding that is required to generate these agents. Now the worksheets are similar to the web forms that you can think of. For example, if it is related to hotel booking, you can think of a form that is there on a website. You can just write GENIE worksheet for that. And then the key thing here is that the developer does not have to work with all the unhappy paths that there might be in this. When this agent is at work, the developer only needs to define all the happy parts. So what are happy parts? We already discussed", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_2021481_ms_-_2088736_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 2021481, "end_ms": 2088736}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 2076105 ms - 2143333 ms", "content": "Title: CS224V Lecture 15 > Transcript > 2076105 ms - 2143333 ms\n\nContent: have to work with all the unhappy paths that there might be in this. When this agent is at work, the developer only needs to define all the happy parts. So what are happy parts? We already discussed that happy parts are the given APIs and all the parameters that the agent can ask the user for. And then there is a runtime system that can handle all the unhappy parts. It uses the knowledge corpus that is given and then also any other agent policy that is provided by the developer in the form of action. We look into like how these actions work later. Now the agent design principles. Now let's talk about when you want to create such an agent. What goes into like what are the things that you want to have in such a such an agent framework? So the first key thing that these agents should have is the developer control. The developer should be able to define different kind of policies. So for example, if you want to give some discount using these agents, you should be able to define discount", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_2076105_ms_-_2143333_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 2076105, "end_ms": 2143333}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 2130613 ms - 2199291 ms", "content": "Title: CS224V Lecture 15 > Transcript > 2130613 ms - 2199291 ms\n\nContent: the developer control. The developer should be able to define different kind of policies. So for example, if you want to give some discount using these agents, you should be able to define discount from maybe a subpopulation of the group or you want to have different kind of discounts at different times. Second thing is they should be responsive to the users. So if the user has any query at any point of time, it should be able to respond to the user and provide the useful information. The third thing is it should be able to support all the knowledge queries. So if you just have an agent which asks for API fields, it is not going to be useful because it should be able to answer to user queries. And using GENIE worksheets, you can we use SQL just a recall, SQL can do search on hybrid data. So if you have free text corpus and or you have free text fields in your database and you have structured field in the database, it can generate or it can find answers for you given any user", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_2130613_ms_-_2199291_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 2130613, "end_ms": 2199291}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 2185039 ms - 2259111 ms", "content": "Title: CS224V Lecture 15 > Transcript > 2185039 ms - 2259111 ms\n\nContent: data. So if you have free text corpus and or you have free text fields in your database and you have structured field in the database, it can generate or it can find answers for you given any user utterance. So it supports the SQL which can handle hybrid data and it is expressive. So we look at examples of this. But sometimes the user might ask for an answer or an answer from a database and also provide the slots or values for the APIs. And finally it should be able to take in a longer conversation and just respond. And it should not forget any of the values that the user has already provided and it should give you the information, the desired information. And the way gnie worksheet does this is using a formal dialogue state tracking and using the worksheet. So the idea is once you have defined the worksheet, it will fill in the values for you within the worksheet in its own representation. And that's what we provide to the user. So now let's look at some of the examples of mixed", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_2185039_ms_-_2259111_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 2185039, "end_ms": 2259111}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 2246871 ms - 2306441 ms", "content": "Title: CS224V Lecture 15 > Transcript > 2246871 ms - 2306441 ms\n\nContent: defined the worksheet, it will fill in the values for you within the worksheet in its own representation. And that's what we provide to the user. So now let's look at some of the examples of mixed initiatives that Gini worksheets can handle. So here's a conversation where the user says, oh, I want to Take an AI course for three unit and a letter grade. The agent finds the AI courses and asks which one of these would you like to take? And finally the user says oh, the math theory for ML looks interesting, I will enroll. And then the agent asks for confirmation that oh, is this the information that you is this the course that you want to enroll in? And is this information correct? So here we can see that there's a user initiative where the user initiates the conversations conversation by saying that oh, can you find me AI courses? And tells the agent oh, I want to take it for three units and for a letter grade. Then there is this agent initiative that once it responds to the user, it", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_2246871_ms_-_2306441_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 2246871, "end_ms": 2306441}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 2294585 ms - 2362875 ms", "content": "Title: CS224V Lecture 15 > Transcript > 2294585 ms - 2362875 ms\n\nContent: saying that oh, can you find me AI courses? And tells the agent oh, I want to take it for three units and for a letter grade. Then there is this agent initiative that once it responds to the user, it asks for the next field that it wants the value for. So which in this case is the course name. And finally there's another example of the agent initiative where the agent asks for confirmation from the user. Now one of the key concept of Gini worksheets and which is very different from others, but it is sort of obvious is that user initiatives are always given priority. So for example, if the user, this is the similar scenario. But if the user, instead of telling the agent which course it wants to take, if it says oh, what is the schedule for CS224V? Then the agent, instead of expecting that the user is giving them answer to their question, it prioritizes the user's initiative and gets the response from the dataset. So here in this case, the highlighted part is the user initiative. So", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_2294585_ms_-_2362875_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 2294585, "end_ms": 2362875}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 2349163 ms - 2417101 ms", "content": "Title: CS224V Lecture 15 > Transcript > 2349163 ms - 2417101 ms\n\nContent: the user is giving them answer to their question, it prioritizes the user's initiative and gets the response from the dataset. So here in this case, the highlighted part is the user initiative. So what Gini worksheet will do, it will execute this query and then come back to the original question that oh, do you want to take this? Then the third important thing that GENIE worksheet does is it provides developer the control. So the develop as we have seen, if you have a dialogue state, a state machine, you have to define all these different kind of these multiple transitions, which can be very difficult for the developer. So using GENIE worksheets, you just declare them in a happy path. The question of why is developer control important? We can divide into like three parts. One is the developer might want control over how the conversation should flow. The developer might want to have when should some action should when a specific action should be taken based on the conversation and what", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_2349163_ms_-_2417101_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 2349163, "end_ms": 2417101}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 2404373 ms - 2470667 ms", "content": "Title: CS224V Lecture 15 > Transcript > 2404373 ms - 2470667 ms\n\nContent: might want control over how the conversation should flow. The developer might want to have when should some action should when a specific action should be taken based on the conversation and what kind of information do you want to like get from the user? So all these can be defined using the developer controllability in Genie worksheets. So let us look at like two very two examples. So here are two scenarios where the student says I want to take CS224V in the fall quarter. Now there can be different agent policies that different developers might want for the same scenario. So in the first one the agent says, unfortunately there are no seats available for CS224V. However, I can find you courses similar to CS224V that are offered in the fall quarter. So this is one kind of developer defined response where the action could be if the course is not available, then suggest other courses. The other scenario is when other scenarios like similar case where there is no seats available for", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_2404373_ms_-_2470667_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 2404373, "end_ms": 2470667}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 2455659 ms - 2532155 ms", "content": "Title: CS224V Lecture 15 > Transcript > 2455659 ms - 2532155 ms\n\nContent: response where the action could be if the course is not available, then suggest other courses. The other scenario is when other scenarios like similar case where there is no seats available for CS224V, the developer can have a. Can have the policy of asking for permission, which I think most of you did. You said that oh, you are graduating soon, so you want the permission code to join CS224V. And you can add this to the agent that okay, if there are no seats you can ask are you graduating soon? If the user says yes and it might just give you the permission code. So here we see two scenarios where d risk the result from the database is the same, but the agent policy is different. And you can define this in GENIE worksheets. So now look at the exam, the GENIE worksheets and how the design of GENIE worksheets. So all of you are like familiar with this. There's GENIE worksheet, you have different fields, you have different worksheets. There are task fields and then there are knowledge", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_2455659_ms_-_2532155_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 2455659, "end_ms": 2532155}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 2518299 ms - 2588305 ms", "content": "Title: CS224V Lecture 15 > Transcript > 2518299 ms - 2588305 ms\n\nContent: of GENIE worksheets. So all of you are like familiar with this. There's GENIE worksheet, you have different fields, you have different worksheets. There are task fields and then there are knowledge fields. The task fields are the APIs that you want to call and the knowledge fields and the knowledge worksheets are the knowledge corpus that you are providing. So the task worksheet, there you define the name of the task, the predicate, the kind of worksheet, is it the task worksheet or is it just for knowledge? And then you define the actions. The actions are triggered once these tasks are completed. Then in each of these tasks there are fields. So all these fields have different attributes such as the predicate. When should this field be asked for the name of the field, the kind, if it is internal, if it is input, if it is internal, then the user cannot edit this field, only the agent can edit it. Then the type of the field, the type of the value and the description, don't ask required", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_2518299_ms_-_2588305_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 2518299, "end_ms": 2588305}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 2576869 ms - 2649057 ms", "content": "Title: CS224V Lecture 15 > Transcript > 2576869 ms - 2649057 ms\n\nContent: if it is input, if it is internal, then the user cannot edit this field, only the agent can edit it. Then the type of the field, the type of the value and the description, don't ask required in confirmation. One key thing to notice here is you require to have semantically meaningful name and description because these are the two things that we provide to the ALM rest. Everything else just goes into the runtime system and it gets executed as a program. And then finally like we have actions for fields as well as tasks and these actions are defined as Python code which give you flexibility of controlling the conversation as you want. And There are three built in actions, say, propose and exit worksheet. The say will force or like it will force the agent to respond with the utterance that you provide inside say propose will propose a new task or the worksheet to fill out from the user. And the exit worksheet is basically abandoning the task. Yeah, and the second type of worksheet that we", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_2576869_ms_-_2649057_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 2576869, "end_ms": 2649057}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 2633091 ms - 2706341 ms", "content": "Title: CS224V Lecture 15 > Transcript > 2633091 ms - 2706341 ms\n\nContent: provide inside say propose will propose a new task or the worksheet to fill out from the user. And the exit worksheet is basically abandoning the task. Yeah, and the second type of worksheet that we have are the knowledge based worksheets. So these can, so these knowledge based worksheet, you basically define your schema in the knowledge based worksheet which can handle. So since we use SQL, it can handle both structured and unstructured database, it can handle free text corpus and the way you define it under the kind you define KB and then rest of it is the same as the task. Okay, so now let's talk about the technical details of Gini worksheets and how do we implement this? So yeah, let's start with the dialogue state tracking. So what does the agent need to do? The agent needs to fill in the values for the fields that are there in the task worksheet, it needs to execute the actions and it needs to perform the queries. And we need to keep track of whatever has happened till let's say", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_2633091_ms_-_2706341_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 2633091, "end_ms": 2706341}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 2693149 ms - 2765553 ms", "content": "Title: CS224V Lecture 15 > Transcript > 2693149 ms - 2765553 ms\n\nContent: the values for the fields that are there in the task worksheet, it needs to execute the actions and it needs to perform the queries. And we need to keep track of whatever has happened till let's say given nth query or the user utterance. And how we do this is we define records as for each of these tasks and knowledge queries. So I'm not sure if you can see this, but the first one is a record of type kb, which means it is from the knowledge base you define the names. So names are basically the tables that you have used for this for the query. Then you define the query in natural language as well as the formal in the formal query which is a SQL query and then you define the result inside it. And for the kind two, the other kind of this record is a task. So these are basically the APIs or the task worksheet that you define. They have a name and then all the parameters are the fields in this worksheet or in this task. So as I mentioned, the records have, they contain name and kind. For", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_2693149_ms_-_2765553_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 2693149, "end_ms": 2765553}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 2752409 ms - 2820961 ms", "content": "Title: CS224V Lecture 15 > Transcript > 2752409 ms - 2820961 ms\n\nContent: the task worksheet that you define. They have a name and then all the parameters are the fields in this worksheet or in this task. So as I mentioned, the records have, they contain name and kind. For tasks they have field names and the values. And for each of the knowledge queries it records the natural language query, the formal query and the result that you get from this query. And only this is provided to the agent for performing the task instead of providing the whole conversation. Now let's look at the agent acts. We have five agents acts in this in GENIE worksheets which are report, confirm, say propose and ask. The report act defines that, okay, this is the query and this is the result and you have to respond to the user telling them, oh, this is what I found. Confirm is when the agent wants to confirm any value from the user. Say is the agent will explicitly mention the utterance that you provide under say to the user. So this is useful when you want to. When you want to just", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_2752409_ms_-_2820961_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 2752409, "end_ms": 2820961}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 2808091 ms - 2880469 ms", "content": "Title: CS224V Lecture 15 > Transcript > 2808091 ms - 2880469 ms\n\nContent: wants to confirm any value from the user. Say is the agent will explicitly mention the utterance that you provide under say to the user. So this is useful when you want to. When you want to just hard code some of the utterances, then propose is to facilitate the developer to propose a new action or to propose a new so for example, let's say the user wants to find a restaurant. And when the agent asks, oh, do you want to book this restaurant? And the user says no, I don't want to, the agent can propose a discount. There can be a discount task sheet or worksheet that is defined and the agent can propose a discount worksheet to be filled out by the user. And you can then provide discount to the user hoping that they'll book the restaurant. And then there is the simple ask agent act which just asks for the value of any field in the worksheet. So now let us look at the architecture for GENIE worksheet. So here's the input that goes into Gini worksheet. For any utterance from the user, we", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_2808091_ms_-_2880469_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 2808091, "end_ms": 2880469}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 2864913 ms - 2936907 ms", "content": "Title: CS224V Lecture 15 > Transcript > 2864913 ms - 2936907 ms\n\nContent: asks for the value of any field in the worksheet. So now let us look at the architecture for GENIE worksheet. So here's the input that goes into Gini worksheet. For any utterance from the user, we provide two natural language utterances. One is the utterance that the user just whatever the user just said right now and one previous dialogue turn. Then we provide two formal inputs. One is the dialogue state and the other one is the agent tag that we just defined. And then finally the GENIE worksheet which specifies the agent policy. And this goes into genie, which has a runtime system which converts the user utterance into a formal representation which can be executed. And it uses LLM for doing semantic parsing and generating response. Let us look into what all of these look like. So we have the natural language input here. So as I mentioned that we provide one turn of dialogue conversation and the current utterance. So let's say the user said I will take HCI course. Can I take it for", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_2864913_ms_-_2936907_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 2864913, "end_ms": 2936907}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 2924977 ms - 2997549 ms", "content": "Title: CS224V Lecture 15 > Transcript > 2924977 ms - 2997549 ms\n\nContent: the natural language input here. So as I mentioned that we provide one turn of dialogue conversation and the current utterance. So let's say the user said I will take HCI course. Can I take it for more than three units? So what we provide to the system is just the at minus 1 which is the previous agent response so that you can contextualize the user entrance better. Then we provide the dialogue state for this scenario. So here we can see that in the dialogue state we have the user, the user has asked for courses in the past. It has information about the course that the user wants to take and some other pre filled information about the courses that it can take. So in the task main it refers to R2, which is a record and that record has course ID. And this course ID needs to be filled using the knowledge Corpus. Apart from that we have the agent acts. So in the agent act we have the report R1 which is reporting, which tells us that in the previous utterance the agent reported the answer", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_2924977_ms_-_2997549_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 2924977, "end_ms": 2997549}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 2984029 ms - 3054983 ms", "content": "Title: CS224V Lecture 15 > Transcript > 2984029 ms - 3054983 ms\n\nContent: the knowledge Corpus. Apart from that we have the agent acts. So in the agent act we have the report R1 which is reporting, which tells us that in the previous utterance the agent reported the answer to the question that show me courses where students are happy with the workload. And it responds with the answer which says CS161 or HCI347. And then the agent asks for, using the R2 record, it asks for the course ID, which course would the user want to take? And since you can see here, the user says I will take HCI course, it can contextualize which HCI course the user is talking about. So this is the input. And now let us look at how GENIE works. So here is a high level architecture of genie where you have the parser and you provide the user utterance to the parser and you give the input that we just defined. It fills in the response from the user in the worksheet which is used for dialogue state tracking. Then there is an agent policy which is the runtime system we look into, like how", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_2984029_ms_-_3054983_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 2984029, "end_ms": 3054983}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 3043983 ms - 3110137 ms", "content": "Title: CS224V Lecture 15 > Transcript > 3043983 ms - 3110137 ms\n\nContent: we just defined. It fills in the response from the user in the worksheet which is used for dialogue state tracking. Then there is an agent policy which is the runtime system we look into, like how this agent policy works and what the agent policy does. It it updates the worksheet and generates the agent acts. Now once you have these agent acts, we use the agent act to generate the response that we provide to the user. So let's look at how the parser works. So the parser basically has three components. One is the contextualized semantic parser, the second is the knowledge based parser, and the third is the update module. So what the contextualized semantic parser does is it takes the natural language utterance from the user and converts it into the worksheet representation. Worksheet representation is basically Python like code where you can define, where you can imagine like each task is the function and all the fields to these tasks are fields. But one key difference from the", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_3043983_ms_-_3110137_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 3043983, "end_ms": 3110137}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 3095497 ms - 3165155 ms", "content": "Title: CS224V Lecture 15 > Transcript > 3095497 ms - 3165155 ms\n\nContent: representation is basically Python like code where you can define, where you can imagine like each task is the function and all the fields to these tasks are fields. But one key difference from the function calling aspect is you can compose different functions with each other. One important design choice that we made was we have a separate knowledge parser. So instead of just adding that to the contextualized semantic parser, we let we basically extract the knowledge query from the user response. So for example, if the user says I want to book a restaurant for Valentine's Day, we will extract the information that user wants to book a restaurant and in some location and only that information is provided. And then you can use other methods such as react based parsers for doing semantic parsing. Or you can just use like a simple LLM call if it is a trivial task. So that is the role of knowledge parser, that it takes the extracted information about the knowledge query that the user has", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_3095497_ms_-_3165155_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 3095497, "end_ms": 3165155}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 3152393 ms - 3217705 ms", "content": "Title: CS224V Lecture 15 > Transcript > 3152393 ms - 3217705 ms\n\nContent: Or you can just use like a simple LLM call if it is a trivial task. So that is the role of knowledge parser, that it takes the extracted information about the knowledge query that the user has made and converts it into a SQL query. And once we have done this parsing, we get the response from the contextualized semantic parser and the knowledge parser and then we execute these programs. So you get a code snippet after you have done the semantic parsing and you can execute it against the current context that you have, which has been defined in the dialogue state tracking. Now here is what the semantic contextualized semantic parser look like. The user can do three kind of. We can define like the three kinds of utterances that the user can make. So the first one is to supply values to an existing worksheet. So you can see like if you have an existing record and the user says that I want to take it for a letter grade, it will just update the letter grade. The user can also modify any", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_3152393_ms_-_3217705_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 3152393, "end_ms": 3217705}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 3205273 ms - 3270721 ms", "content": "Title: CS224V Lecture 15 > Transcript > 3205273 ms - 3270721 ms\n\nContent: existing worksheet. So you can see like if you have an existing record and the user says that I want to take it for a letter grade, it will just update the letter grade. The user can also modify any previously filled value or remove its value. So for example, the user can say, oh, on the second thought I will take it for four units. What it does is it just updates the field value and updates the field value for number of units and it changes it to four units. The third thing that the user can do is initiate a new task or a new query. So what happens here is the user asks what is the maximum number of units I can take it for? So in this case a new record will be generated which is of kind kb, which tells us that oh, the user has asked a question and we need to fetch this answer from the database. Now as I just mentioned, the task of the knowledge parser is to take the user's natural language query and convert it into a queryable or like a query that you can execute against a database.", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_3205273_ms_-_3270721_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 3205273, "end_ms": 3270721}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 3255185 ms - 3326093 ms", "content": "Title: CS224V Lecture 15 > Transcript > 3255185 ms - 3326093 ms\n\nContent: Now as I just mentioned, the task of the knowledge parser is to take the user's natural language query and convert it into a queryable or like a query that you can execute against a database. And it can, you can just. So this helps in abstraction and you can have different kinds of parser for if you have like different or difficult or challenges data sets or databases, you can use the REACT parser. So for example, in a case such as a restaurant agent, you can just have like a simple LLM and it will generate the SQL for you using just one LLM call. However, when we created the course assistant, we found that there's a lot of domain specific information involved in the courses. It has four tables, it has thousands of rows and in those cases it is slightly more difficult for the LM to generate the SQL query in just one pass. So we use the REACT agent which can look at its answer, it can explore the database a bit more and then generate the final query. And this react based parser is", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_3255185_ms_-_3326093_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 3255185, "end_ms": 3326093}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 3309317 ms - 3380755 ms", "content": "Title: CS224V Lecture 15 > Transcript > 3309317 ms - 3380755 ms\n\nContent: the SQL query in just one pass. So we use the REACT agent which can look at its answer, it can explore the database a bit more and then generate the final query. And this react based parser is similar to the Spanish parser that we saw two Lectures back. So this basically provides the abstraction from the contextualized semantic parser, just so that we can do this in a better way. And this also tells us that, and we have already seen that when you're working with LLMs, it is better to decompose your tasks and giving them modular tasks or like atomic tasks, so that they can do that better. So once we have done the semantic parsing, then we come to the agent policy and how it works. I've already mentioned that once we get the representation in the worksheet format, then we execute it against the runtime system. But then comes the question of what should the agent do next? So the agent policy. So one key aspect is that we don't let the LLM generate the response directly by looking at the", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_3309317_ms_-_3380755_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 3309317, "end_ms": 3380755}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 3365571 ms - 3442245 ms", "content": "Title: CS224V Lecture 15 > Transcript > 3365571 ms - 3442245 ms\n\nContent: the runtime system. But then comes the question of what should the agent do next? So the agent policy. So one key aspect is that we don't let the LLM generate the response directly by looking at the user's utterance or the response from getting information from a database. What we do is we use the GENIE runtime system to compute the agent response. And how we do this is it first runs the knowledge queries, it performs all the actions that have been defined by the developer, and it generates the agent acts that we just. That we look some slides. So there were five agents acts, report, confirm, say, propose and ask. So it generates, it can generate multiple agent acts. And so what is the rationale behind having this symbolic like agent policy and a runtime system instead of just having an ALM decide the policy? So the first point is that when you have some policy which might be underrepresented in the wild, it is very difficult for the LLM to come up with those kind of responses to the", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_3365571_ms_-_3442245_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 3365571, "end_ms": 3442245}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 3425787 ms - 3495337 ms", "content": "Title: CS224V Lecture 15 > Transcript > 3425787 ms - 3495337 ms\n\nContent: decide the policy? So the first point is that when you have some policy which might be underrepresented in the wild, it is very difficult for the LLM to come up with those kind of responses to the user. So, for example, as we just saw, like the developer can define two different kinds of policies when a course is not available. In that case you can just, you can. So with GENIE worksheets, you can define those two different scenarios by just replacing the agent policy. But with the LLM, it might struggle when you have a policy that is not represented well enough. The second example is as you create these agents, there might be several instructions that you want to put into this agent. And in my experience, when you have more than five to six instructions in the prompt, it usually does not work well. So what we try to do with the agent policy is that you can think of it as providing the correct instruction at the correct point of time, which helps the semantic parser generate the", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_3425787_ms_-_3495337_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 3425787, "end_ms": 3495337}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 3478933 ms - 3552263 ms", "content": "Title: CS224V Lecture 15 > Transcript > 3478933 ms - 3552263 ms\n\nContent: not work well. So what we try to do with the agent policy is that you can think of it as providing the correct instruction at the correct point of time, which helps the semantic parser generate the worksheet. And then based on the state of the conversation, you execute different kind of actions. What this helps us with is we generate the agent acts which are deterministic. And you can also look at, oh, where is the system failing and how can we improve this? By maybe changing the agent policy? Or maybe the semantic parser is not working. You might want to add in some examples there. So using the symbolic module to compute the necessary action, we can improve the LLM based system's ability to follow these instructions. Now let's look at what the runtime system looks like. So we saw that we have the parser which assigns values to the worksheet and generates the database queries. Now the agent policy looks like this. So the goal is to have the final set of dialogue acts. It'll first look", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_3478933_ms_-_3552263_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 3478933, "end_ms": 3552263}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 3537551 ms - 3602647 ms", "content": "Title: CS224V Lecture 15 > Transcript > 3537551 ms - 3602647 ms\n\nContent: have the parser which assigns values to the worksheet and generates the database queries. Now the agent policy looks like this. So the goal is to have the final set of dialogue acts. It'll first look at the knowledge query and if there are any missing parameters in the knowledge query, it will add ask for the parameter to the agent act. If the query is complete, it will then just execute the agent policy or it will execute the query against the database. Then once we are done with the knowledge query and we execute the knowledge query first because as I mentioned that we prioritize users initiative, that's why we have the knowledge query first. And once that is done then we go to the worksheets. Now what this worksheet does is it first asks for confirmation if any of the field requires a confirmation and it adds that oh, ask for confirmation to the agent ads. Then it checks if any of the fields or the worksheets are complete. And if they are complete, then it executes the action that", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_3537551_ms_-_3602647_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 3537551, "end_ms": 3602647}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 3588213 ms - 3657475 ms", "content": "Title: CS224V Lecture 15 > Transcript > 3588213 ms - 3657475 ms\n\nContent: confirmation and it adds that oh, ask for confirmation to the agent ads. Then it checks if any of the fields or the worksheets are complete. And if they are complete, then it executes the action that are defined by the user, by the developer. And then finally if there are any fields for which we don't have the values, then the agent asks for these fields. So this is defined, currently defined by us and this is the agent policy. But if the developer wants to tune this, they can do this by adding different actions in like python, like code and using the agent response, it then generates, using the agent act it generates the response. So we come to the final part which is the update. Once you have the updated worksheets and the agent acts, then you can just generate the response. So it is a very simple module in our system which just takes the agent acts and generates the response. Here are three different examples of the agent acts. The first one just says ask field. So what it is doing", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_3588213_ms_-_3657475_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 3588213, "end_ms": 3657475}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 3645551 ms - 3716207 ms", "content": "Title: CS224V Lecture 15 > Transcript > 3645551 ms - 3716207 ms\n\nContent: simple module in our system which just takes the agent acts and generates the response. Here are three different examples of the agent acts. The first one just says ask field. So what it is doing is it is asking for the agent will ask the user to confirm the book restaurant object and it is asking for confirmation for all the parameters in the book restaurant API call. The report response provides the result of the answer query that the agent made and then the proposed worksheet which is if the agent wants to propose to book a new restaurant with some restaurant fields. So this is what we provide to the LM and it generates the response based on the state or the dialogue state at that point. So Gini worksheets can support like these different kind of, these different and challenging scenarios. It allows for data dependent field, it can complete multiple tasks at once, it supports multiple knowledge queries in a single utterance, it can keep track of all the essential information that", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_3645551_ms_-_3716207_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 3645551, "end_ms": 3716207}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 3703687 ms - 3770871 ms", "content": "Title: CS224V Lecture 15 > Transcript > 3703687 ms - 3770871 ms\n\nContent: It allows for data dependent field, it can complete multiple tasks at once, it supports multiple knowledge queries in a single utterance, it can keep track of all the essential information that you have provided and it asks for tasks and it can support task, it can support composition of task and knowledge in a second in a single utterance, and finally allow for unhappy paths. So here's just some examples of these different, these different conversations that you can have that can, that are supported by Gini worksheets and cannot be supported by some of the existing works out there. So the first one is the composition of query and APIs. So as I mentioned, if the user says that I want to book an Italian restaurant in New York City for two on Valentine's Day, in the red we have the worksheet representation, and in blue we have the knowledge base query. And you can easily compose these together in a sustained representation. The second one is when you want to perform multiple tasks or", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_3703687_ms_-_3770871_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 3703687, "end_ms": 3770871}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 3758767 ms - 3820529 ms", "content": "Title: CS224V Lecture 15 > Transcript > 3758767 ms - 3820529 ms\n\nContent: representation, and in blue we have the knowledge base query. And you can easily compose these together in a sustained representation. The second one is when you want to perform multiple tasks or fill out multiple fields. For example, here you have three units in letter grade, you want to fill out two different slots in that. And this is what you can do easily with GENIE worksheets. It also allows for data dependent fields. So one of the drawbacks of function calling is another drawback of function calling is that you cannot have data dependent fields. So for example, if the agent asks the user, are you an international student? Based on the value of the based on the user's response, you can ask different questions. So this can be defined in a single query. And how we do this is like you can have a predicate that, okay, if the user is an international student only, then you have to ask that what type of visa is it? Is it F1 or a J1 visa? Then it can support multiple knowledge queries", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_3758767_ms_-_3820529_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 3758767, "end_ms": 3820529}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 3807081 ms - 3873777 ms", "content": "Title: CS224V Lecture 15 > Transcript > 3807081 ms - 3873777 ms\n\nContent: can have a predicate that, okay, if the user is an international student only, then you have to ask that what type of visa is it? Is it F1 or a J1 visa? Then it can support multiple knowledge queries at once. So for example, if the user asks, what are some highly rated NLP courses? Also, when does the next semester start? You can have two answer functions and the agent will fetch response for both of these questions and respond with the answer. Then the other example is when the user wants to change their previous answer. So if the user says that I want to fly from New York to Los Angeles on 8th, and the agent finds some results corresponding to this, the agent, the user can then change their answer. And once they change their answer, oh, I'm looking for the 9th instead of 8th, the agent will then recompute the query and respond with the new flights that it can find. So finally we'll go into how do we evaluate GENIE agents. But before we do that, you can scan this QR code for your", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_3807081_ms_-_3873777_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 3807081, "end_ms": 3873777}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 3860393 ms - 3948067 ms", "content": "Title: CS224V Lecture 15 > Transcript > 3860393 ms - 3948067 ms\n\nContent: will then recompute the query and respond with the new flights that it can find. So finally we'll go into how do we evaluate GENIE agents. But before we do that, you can scan this QR code for your attendance. I'll give a minute. You can just click the picture and like fill it out later. I think everyone is done. So let, let us look at how can you evaluate these task oriented agents and how did we evaluate Gini worksheets? So there we already talked about multi wars. One of the challenges with multi wars was it does not have unhappy paths, it only has happy paths in it and it is too trivial of a data set. So we look at STAR data set which contains 13 domains and it has 22 tasks in these different 13 domains. And the problem in this benchmark or like the task for this in this benchmark is that you have to predict the next action that the agent needs to take. And the STAR dataset also provides a policy that you can that outlines the conversation flow. You already saw this policy when you", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_3860393_ms_-_3948067_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 3860393, "end_ms": 3948067}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 3936211 ms - 4004877 ms", "content": "Title: CS224V Lecture 15 > Transcript > 3936211 ms - 4004877 ms\n\nContent: you have to predict the next action that the agent needs to take. And the STAR dataset also provides a policy that you can that outlines the conversation flow. You already saw this policy when you worked with the assignment 2. All of you were given an agent graph and that is what the STAR dataset provides. However, instead of using Star dataset we use Star V2, which improves the STAR dataset by making some new annotations to this state belief and the state annotations. And it also adds some intuitive natural language description for the schema which helps different models in performing these tasks in zero shot. Now let's look at the evaluation metrics that are there for this data set. You can have the user action F1 which is basically the mapping of the user's natural language to the user dialogue act. Then you have the system action F1 which is again which calculates the F1 score for agents utterance based on the action that the agent takes or the agent acts. And then finally it has", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_3936211_ms_-_4004877_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 3936211, "end_ms": 4004877}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 3989925 ms - 4065571 ms", "content": "Title: CS224V Lecture 15 > Transcript > 3989925 ms - 4065571 ms\n\nContent: dialogue act. Then you have the system action F1 which is again which calculates the F1 score for agents utterance based on the action that the agent takes or the agent acts. And then finally it has the joint goal accuracy which defines the which calculates the accuracy of the current belief state at any given turn. So let us. So we evaluated on three domains and the three domains that we evaluated were Bank, Trivia and Trip. You will recognize that we did not provide this to. We did not ask you to do these three domains because they are kind of challenging according to the data set. And so what the state of the art for this data set is any Todd they fine tuned T5 a 13 billion parameter model on 6000 points. And for each domain they train on all the other domains except the one that they are testing. And they also define an agent policy which is written in Python. And here are the results. But the question is, is this good enough? If you are Getting a score of 65, 62.9 or 86.3 if you", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_3989925_ms_-_4065571_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 3989925, "end_ms": 4065571}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 4048331 ms - 4121361 ms", "content": "Title: CS224V Lecture 15 > Transcript > 4048331 ms - 4121361 ms\n\nContent: are testing. And they also define an agent policy which is written in Python. And here are the results. But the question is, is this good enough? If you are Getting a score of 65, 62.9 or 86.3 if you want to use them in production. These scores are actually not at all usable. So let us look at the Gini agents results. So one important thing is you can just define the program logic that any Todd wrote and they wrote it in 32 lines. You can just write them in like eight or nine lines of code. We provide just three examples instead of fine tuning our agent for each of these domains and we achieve a score of 82, 83 and 92.7. And I would say like this is also not good enough. However when we looked at the errors, the most of the errors were due to the agent not following the agent policy that was described because again these are manually annotated and most of the errors were due to these inconsistent data annotation. So this task was very, I would say like it was kind of easy for GENIE to", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_4048331_ms_-_4121361_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 4048331, "end_ms": 4121361}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 4107849 ms - 4176151 ms", "content": "Title: CS224V Lecture 15 > Transcript > 4107849 ms - 4176151 ms\n\nContent: described because again these are manually annotated and most of the errors were due to these inconsistent data annotation. So this task was very, I would say like it was kind of easy for GENIE to work with. However, I would also want to point out that they are like several limitations of such a data set. One, it has just simple domains with just slot value filling task as you can recall, like function call. We just discussed that function calling is not enough for all these different kind of tasks, especially when you want to query different databases. Next it requires you to evaluate just turn wise performance. And the third one, it contains only very few unhappy paths. So as I mentioned earlier, similar to multivas, they give a script to the user that they have to follow and these contain very few unhappy paths. And again there are annotation problems. So how we evaluate GENIE worksheets is using real users. So we choose three domains with varying complexity. The first one was the", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_4107849_ms_-_4176151_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 4107849, "end_ms": 4176151}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 4160279 ms - 4230341 ms", "content": "Title: CS224V Lecture 15 > Transcript > 4160279 ms - 4230341 ms\n\nContent: very few unhappy paths. And again there are annotation problems. So how we evaluate GENIE worksheets is using real users. So we choose three domains with varying complexity. The first one was the restaurant reservation where we use a real life database from Yelp. This was the similar one that was used by Yale Bot. Then the second one was a ticket submission. So this is similar to the ServiceNow platform that we have at Stanford, but a subset of it. So it contains several APIs, not all the APIs however. So here we wanted to see how does it scale when you have multiple APIs. And then finally the course enrollment domain which all of you tried, it contains the courses from the MSCS courses or mostly like computer science courses and from Stanford and contains several fields. So this combines multiple fields with a large database. And you can see like the difference between Star v2 and the real domains that we evaluated with Star v2 has no knowledge corpus. There are like several", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_4160279_ms_-_4230341_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 4160279, "end_ms": 4230341}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 4216653 ms - 4297411 ms", "content": "Title: CS224V Lecture 15 > Transcript > 4216653 ms - 4297411 ms\n\nContent: combines multiple fields with a large database. And you can see like the difference between Star v2 and the real domains that we evaluated with Star v2 has no knowledge corpus. There are like several knowledge corpus in these three domains. There are way more fields than you would expect that you will find in Star v2 which you find in these in the three domains. That we evaluated. So this is a real life exper like so the whole so what it boils down to that you need to use real life domains for evaluation and you cannot just stay with like academic data sets such as Star V2. So for this, the baseline that we use for our Evaluation was a GPT4 Turbo based system which uses function calling. And the key or the important part to note here is that we provided the knowledge based parser to the GPT4 Turbo, which is the same one that we use with GENIE worksheet. So this kind of makes GPT4 Turbo and even better at just off the shelf system that you can create. For the study we recruited 22 and", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_4216653_ms_-_4297411_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 4216653, "end_ms": 4297411}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 4282449 ms - 4351703 ms", "content": "Title: CS224V Lecture 15 > Transcript > 4282449 ms - 4351703 ms\n\nContent: Turbo, which is the same one that we use with GENIE worksheet. So this kind of makes GPT4 Turbo and even better at just off the shelf system that you can create. For the study we recruited 22 and 20 users from ProLife for the restaurant reservation and ticket submission domains. However, we recruited 20 university students from Stanford so that they are aware of the courses that you can take and they can try out or challenge the agent a bit more than someone that you can recruit from a crowdsourcing platform. And then we randomly assign Genie Agent and GPT4 with function calling ability to these users. Now before we move into the results, let us look at the evaluation metric. So these differ slightly from the ones that we saw for Star V2. So for example, the first one is the semantic parsing accuracy. As you will note that we don't use the user acts, we just generate the representation in the worksheet representation. Therefore we have the semantic parsing accuracy which calculates", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_4282449_ms_-_4351703_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 4282449, "end_ms": 4351703}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 4338527 ms - 4404797 ms", "content": "Title: CS224V Lecture 15 > Transcript > 4338527 ms - 4404797 ms\n\nContent: accuracy. As you will note that we don't use the user acts, we just generate the representation in the worksheet representation. Therefore we have the semantic parsing accuracy which calculates the set of. It basically calculates if you got the API calls correct, if you got the database call correct, and if all the fields that you have are correctly filled, then the second one is the execution accuracy. This is here and it was not there in Star V2 because Star V2 does not handle databases. And this basically denotes if you call the correct APIs with the correct parameters and if you call the correct database with the correct query. The third one is the agent dialogue accuracy, which is similar to the system action accuracy from Star V2. And then finally we have another metric which is the goal completion rate. So here we check if the user was able to complete the goal that they wanted to do, which is again not present in Star V2 evaluation. Now let us look at the results. So here is", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_4338527_ms_-_4404797_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 4338527, "end_ms": 4404797}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 4390961 ms - 4468209 ms", "content": "Title: CS224V Lecture 15 > Transcript > 4390961 ms - 4468209 ms\n\nContent: goal completion rate. So here we check if the user was able to complete the goal that they wanted to do, which is again not present in Star V2 evaluation. Now let us look at the results. So here is the aggregated result for all the domain. We get 82.8% accuracy on the goal completion, which is very low for GPT4 function calling. One thing. So here we see that if you have a compressed context as like a formal dialog state, it enables the LLM to invoke the correct APIs instead of just providing the whole conversations and most of these conversations had more than 10 user terms. One important thing to see here is that all the multi wars star v2 there are other data sets as well such as SGD they all of them have restaurant as a common domain in the dataset and we can see that since it is common to academic dataset, the performance in the restaurant domain is slightly higher of GPT4 as compared to other domains. It is able to complete more tasks as compared to other domains and one key", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_4390961_ms_-_4468209_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 4390961, "end_ms": 4468209}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 4454361 ms - 4524571 ms", "content": "Title: CS224V Lecture 15 > Transcript > 4454361 ms - 4524571 ms\n\nContent: to academic dataset, the performance in the restaurant domain is slightly higher of GPT4 as compared to other domains. It is able to complete more tasks as compared to other domains and one key information that or like analysis. So when we were looking at oh where is GPT4 getting things wrong Especially in the course enrollment setting where you see that the goal completion accuracy is just 10% we saw that the GPT4 based system was calling APIs with unknown courses which are not there in the database and just executing the API queries which fails. So I will so let me just conclude today's lecture. So we have already established that LLMs need succinct to represent context and fewer instructions to make them perform better in lesser known domains as we just saw that it performs good with restaurants but fails in the ticket submission and the course enrollment domains. Then we also saw GENIE worksheet in action and how you can create reliable and responsive agents by having a formal", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_4454361_ms_-_4524571_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 4454361, "end_ms": 4524571}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 4511563 ms - 4572005 ms", "content": "Title: CS224V Lecture 15 > Transcript > 4511563 ms - 4572005 ms\n\nContent: restaurants but fails in the ticket submission and the course enrollment domains. Then we also saw GENIE worksheet in action and how you can create reliable and responsive agents by having a formal dialogue state which compresses the full conversation and having a runtime system which will execute all the agent policies that are defined by the developer. And finally I would say that the existing academic data set, at least for task oriented agents, are not enough for evaluation. Whenever you and you are creating like different agents for your class project, you need to evaluate them with real users. You need to evaluate them by asking difficult questions and only then you'll get to know if they're working well or not. You cannot just rely on an academic dataset which has exist which has like limited set of user utterances and just limited set of mappings and they don't really challenge your agents, especially in the new age of LLM where they can handle different kind of different", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_4511563_ms_-_4572005_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 4511563, "end_ms": 4572005}}
{"document_title": "CS224V Lecture 15", "section_title": "CS224V Lecture 15 > Transcript > 4560045 ms - 4782605 ms", "content": "like limited set of user utterances and just limited set of mappings and they don't really challenge your agents, especially in the new age of LLM where they can handle different kind of different scenarios. And I think that's it. I think that's it for today. We'll see see on Wednesday we'll have Jackie Yang from he just graduated from a group. He'll talk about multimodal apps and he'll be taking the lecture and I'll see you guys on Monday. Thank you. It it.", "block_metadata": {"id": "CS224V_Lecture_15_>_Transcript_>_4560045_ms_-_4782605_ms", "document_type": "transcript", "lecture_number": 15, "start_ms": 4560045, "end_ms": 4782605}}
